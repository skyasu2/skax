"""
PlanCraft Agent - Writer Agent (ì‘ê°€)

ì‹¤ì§ˆì ì¸ ê¸°íšì„œ ë³¸ë¬¸ì„ ì‘ì„±í•˜ëŠ” í•µì‹¬ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
êµ¬ì¡°í™”ëœ ëª©ì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì„¹ì…˜ì— ë“¤ì–´ê°ˆ ë‚´ìš©ì„ ì±„ìš°ë©°, ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•©ë‹ˆë‹¤.

[Key Capabilities]
1. ì ì‘í˜• ì‘ì„± ì „ëµ (Adaptive Writing Strategy):
   - Fast/Balanced: ì†ë„ë¥¼ ìœ„í•´ í•œ ë²ˆì— ì „ì²´ë¥¼ ì‘ì„±í•˜ëŠ” Single-shot ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
   - Quality: ë‚´ìš© ì†ì‹¤(Context Loss)ì„ ë§‰ê¸° ìœ„í•´ 3ê°œ ì„¹ì…˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ëŠ” Chunk Writing ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
2. ëŠ¥ë™ì  ë°ì´í„° í†µí•©:
   - RAG(Vector DB) ë° ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰(Active Search) ê²°ê³¼ë¥¼ ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ëƒ…ë‹ˆë‹¤.
   - Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë° ì‹œê° ìë£Œ ì½”ë“œë¥¼ ìƒì„±í•˜ì—¬ ë¬¸ì„œì˜ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.
"""
from langchain_core.messages import SystemMessage, HumanMessage
from utils.llm import get_llm
from utils.schemas import DraftResult
from utils.time_context import get_time_context, get_time_instruction
from graph.state import PlanCraftState, update_state, ensure_dict
from utils.settings import settings
from utils.file_logger import get_file_logger

# í—¬í¼ í•¨ìˆ˜ ì„í¬íŠ¸ (Refactored)
from agents.writer_helpers import (
    get_prompts_by_doc_type,
    execute_web_search,
    execute_specialist_agents,
    build_visual_instruction,
    build_visual_feedback,
    build_review_context,
    build_refinement_context,
    validate_draft
)


def run(state: PlanCraftState) -> PlanCraftState:
    """
    ì´ˆì•ˆ ì‘ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰

    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (structure í•„ìˆ˜)

    Returns:
        PlanCraftState: draft í•„ë“œê°€ ì¶”ê°€ëœ ìƒíƒœ
    """
    logger = get_file_logger()

    # 1. ì…ë ¥ ê²€ì¦
    user_input = state.get("user_input", "")
    structure = state.get("structure")
    if not structure:
        return update_state(state, error="êµ¬ì¡°í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2. ì„¤ì • ë¡œë“œ
    from utils.settings import get_preset
    active_preset = state.get("generation_preset", settings.active_preset)
    preset = get_preset(active_preset)
    refine_count = state.get("refine_count", 0)

    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í—¬í¼ í•¨ìˆ˜ ìœ„ì„)
    rag_context = state.get("rag_context", "")
    web_context = state.get("web_context", "")

    # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
    web_context = execute_web_search(user_input, rag_context, web_context, logger)

    # ì „ë¬¸ ì—ì´ì „íŠ¸ ë¶„ì„
    specialist_context, state = execute_specialist_agents(
        state, user_input, web_context, refine_count, logger
    )

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt, user_prompt_template = get_prompts_by_doc_type(state)
    visual_instruction = build_visual_instruction(preset, logger)

    # User Constraints ì¶”ì¶œ
    user_constraints_str = "ì—†ìŒ"
    analysis_obj = state.get("analysis")
    if analysis_obj:
        u_constraints = analysis_obj.get("user_constraints", []) if isinstance(analysis_obj, dict) \
            else getattr(analysis_obj, "user_constraints", [])
        if u_constraints:
            user_constraints_str = "\n".join([f"- {c}" for c in u_constraints])

    # Web URLs í¬ë§·íŒ…
    web_urls = state.get("web_urls", [])
    web_urls_str = "\n".join([f"- {url}" for url in web_urls]) if web_urls else "ì—†ìŒ"

    try:
        formatted_prompt = user_prompt_template.format(
            user_input=user_input,
            structure=str(structure),
            web_context=web_context if web_context else "ì—†ìŒ",
            web_urls=web_urls_str,
            context=rag_context if rag_context else "ì—†ìŒ",
            visual_instruction=visual_instruction,
            user_constraints=user_constraints_str
        )
        
        # [NEW] Quality ëª¨ë“œ ì „ìš© ì¶”ê°€ ì§€ì¹¨ (ì–‘ì  í’ì„±í•¨ ê°•í™”)
        if preset.name == "quality":
            quality_instruction = """
\n=====================================================================
ğŸ‘‘ **[Quality Mode] ìµœê³  í’ˆì§ˆ ì‘ì„± ì§€ì¹¨**
1. **í•µì‹¬ ê¸°ëŠ¥(Key Features)**: ë°˜ë“œì‹œ **6ê°œ ì´ìƒ**ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ìƒì„¸íˆ ê¸°ìˆ í•˜ì„¸ìš”.
2. **ì„¹ì…˜ ë¶„ëŸ‰**: ê° ì„¹ì…˜ì€ ìµœì†Œ 500ì ì´ìƒ, ê¹Šì´ ìˆëŠ” ë‚´ìš©ì„ ë‹´ìœ¼ì„¸ìš”.
3. **ì°¸ê³  ìë£Œ**: ì¸ìš©ëœ ëª¨ë“  ì¶œì²˜ë¥¼ ë§ˆì§€ë§‰ì— 'ì°¸ê³  ìë£Œ' ì„¹ì…˜ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
=====================================================================\n
"""
            formatted_prompt += quality_instruction

    except KeyError as e:
        return update_state(state, error=f"í”„ë¡¬í”„íŠ¸ í¬ë§· ì˜¤ë¥˜: {str(e)}")

    # ì „ë¬¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ì£¼ì…
    if specialist_context:
        specialist_header = f"""
=====================================================================
ğŸ¤– ì „ë¬¸ ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼ (ë°˜ë“œì‹œ í™œìš©í•  ê²ƒ!)
=====================================================================
{specialist_context}
=====================================================================
"""
        formatted_prompt = specialist_header + formatted_prompt

    # Refinement ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    review_context = build_review_context(state, refine_count)
    refinement_context = build_refinement_context(refine_count, preset.min_sections)

    # Refinement Strategy
    strategy_msg = ""
    refinement_guideline = state.get("refinement_guideline")
    if refine_count > 0 and refinement_guideline:
        direction = refinement_guideline.get("overall_direction", "") if isinstance(refinement_guideline, dict) \
            else getattr(refinement_guideline, "overall_direction", "")
        guidelines = refinement_guideline.get("specific_guidelines", []) if isinstance(refinement_guideline, dict) \
            else getattr(refinement_guideline, "specific_guidelines", [])
        strategy_msg = f"ğŸš€ ë°©í–¥: {direction}\nì§€ì¹¨: {chr(10).join([f'- {g}' for g in guidelines])}\n"

    prepend_msg = strategy_msg + review_context + refinement_context
    formatted_prompt = prepend_msg + formatted_prompt + get_time_instruction()

    # 5. LLM í˜¸ì¶œ (Self-Reflection Loop)
    messages = [
        {"role": "system", "content": get_time_context() + system_prompt},
        {"role": "user", "content": formatted_prompt}
    ]

    writer_llm = get_llm(
        model_type=preset.model_type,
        temperature=preset.temperature
    ).with_structured_output(DraftResult)

    max_retries = preset.writer_max_retries
    final_draft_dict = None
    last_draft_dict = None
    last_error = None

    # [NEW] Quality ëª¨ë“œì¼ ê²½ìš°: ë¶„í•  ì‘ì„± (Chunk Writing)
    if active_preset == "quality" and structure:
        logger.info("[Writer] ğŸ‘‘ Quality Mode: Chunk Writing ì‹œì‘ (ì„¹ì…˜ë³„ ìƒì„¸ ì‘ì„±)")
        try:
            final_draft_dict = _write_in_chunks(
                writer_llm, 
                messages, 
                structure, 
                logger
            )
            # Chunk Writing ê²°ê³¼ëŠ” ì´ë¯¸ Qualityê°€ í™•ë³´ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³  loop break
            # ë‹¨, ê¸°ë³¸ì ì¸ í¬ë§· ê²€ì¦ì€ í•œ ë²ˆ ìˆ˜í–‰
            issues = validate_draft(final_draft_dict, preset, specialist_context, refine_count, logger)
            if issues:
                logger.warning(f"[Writer] Chunk Writing ê²€ì¦ ì´ìŠˆ(ë¬´ì‹œë¨): {issues}")
            
            return update_state(state, draft=final_draft_dict, current_step="write")
        except Exception as e:
            logger.error(f"[Writer] Chunk Writing ì‹¤íŒ¨: {e}, Fallback to Standard Mode")
            # ì‹¤íŒ¨ ì‹œ ì•„ë˜ í‘œì¤€ ëª¨ë“œë¡œ ì§„í–‰ (Fallback)

    # [Standard Mode] í†µìœ¼ë¡œ ì‘ì„± (Fast/Balanced or Quality Fallback)
    for current_try in range(max_retries):
        try:
            logger.info(f"[Writer] ì´ˆì•ˆ ì‘ì„± ì‹œë„ ({current_try + 1}/{max_retries})...")
            draft_result = writer_llm.invoke(messages)
            draft_dict = ensure_dict(draft_result)
            last_draft_dict = draft_dict

            # Self-Reflection ê²€ì¦ (í—¬í¼ í•¨ìˆ˜ ìœ„ì„)
            validation_issues = validate_draft(
                draft_dict, preset, specialist_context, refine_count, logger
            )

            if validation_issues:
                logger.warning(f"[Writer] ê²€ì¦ ì‹¤íŒ¨: {', '.join(validation_issues)}")

                # ì‹œê°ì  ìš”ì†Œ ëˆ„ë½ ì‹œ êµ¬ì²´ì ì¸ ì˜ˆì‹œ í”¼ë“œë°± ì¶”ê°€
                visual_feedback = build_visual_feedback(validation_issues, preset)
                base_feedback = f"[ê²€ì¦ ì‹¤íŒ¨] {', '.join(validation_issues)}. ëª¨ë“  ì„¹ì…˜ì„ ì™„ì „íˆ ì‘ì„±í•˜ì„¸ìš”."
                feedback = base_feedback + visual_feedback if visual_feedback else base_feedback

                messages.append({"role": "user", "content": feedback})
                last_error = f"ê²€ì¦ ì‹¤íŒ¨: {', '.join(validation_issues)}"
                continue

            # í†µê³¼
            final_draft_dict = draft_dict
            section_count = len(draft_dict.get("sections", []))
            logger.info(f"[Writer] âœ… Self-Check í†µê³¼ (ì„¹ì…˜ {section_count}ê°œ)")
            break

        except Exception as e:
            logger.error(f"[Writer Error] {e}")
            last_error = str(e)

    # 6. ê²°ê³¼ ë°˜í™˜
    if final_draft_dict:
        return update_state(state, draft=final_draft_dict, current_step="write")
    elif last_draft_dict:
        logger.warning("[Writer] âš ï¸ ë¶€ë¶„ ê²°ê³¼ ì‚¬ìš©")
        return update_state(state, draft=last_draft_dict, current_step="write")
    else:
        return update_state(state, error=f"Writer ì‹¤íŒ¨: {last_error}")


def _write_in_chunks(llm, base_messages, structure_obj, logger):
    """
    [Quality Mode ì „ìš©] ì„¹ì…˜ì„ ë‚˜ëˆ„ì–´ ì‘ì„±í•œ í›„ ë³‘í•©í•©ë‹ˆë‹¤.
    
    Args:
        llm: Writer LLM
        base_messages: ê¸°ë³¸ ì‹œìŠ¤í…œ/ìœ ì € ë©”ì‹œì§€
        structure_obj: Structurer ì¶œë ¥ ê°ì²´ (sections ë¦¬ìŠ¤íŠ¸ í¬í•¨)
        logger: ë¡œê±°
        
    Returns:
        dict: í•©ì³ì§„ DraftResult ë”•ì…”ë„ˆë¦¬
    """
    import copy
    
    sections = structure_obj.get("sections", []) if isinstance(structure_obj, dict) else getattr(structure_obj, "sections", [])
    if not sections:
        raise ValueError("êµ¬ì¡°ì— ì„¹ì…˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    full_draft = {
        "title": getattr(structure_obj, "title", "Business Plan"),
        "sections": [],
        "key_features": [] # ë‚˜ì¤‘ì— ì²« ì²­í¬ì—ì„œ ê°€ì ¸ì˜´
    }
    
    # ì²­í¬ ì‚¬ì´ì¦ˆ: 3ê°œ ì„¹ì…˜ì”©
    chunk_size = 3
    total_sections = len(sections)
    
    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸(base_messages[-1])ì—ì„œ ê¸°ë³¸ ì§€ì‹œì‚¬í•­ ì¶”ì¶œ
    base_user_content = base_messages[-1]["content"] if base_messages else ""
    
    for i in range(0, total_sections, chunk_size):
        chunk_sections = sections[i : i + chunk_size]
        chunk_titles = [s.get("title", s) if isinstance(s, dict) else str(s) for s in chunk_sections]
        
        logger.info(f"[Writer Chunk] ì„¹ì…˜ {i+1}~{min(i+chunk_size, total_sections)} ì‘ì„± ì¤‘: {chunk_titles}")
        
        chunk_instruction = f"""
\n=====================================================================
ğŸ§© **[Section Writing Phase {i//chunk_size + 1}]**
ì „ì²´ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšì„œ ì¤‘ ì•„ë˜ ì„¹ì…˜ë“¤ë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ì ˆëŒ€ ë‹¤ë¥¸ ì„¹ì…˜ì„ ê±´ë„ˆë›°ê±°ë‚˜ í•©ì¹˜ì§€ ë§ˆì„¸ìš”.

**ì‘ì„± ëŒ€ìƒ ì„¹ì…˜**:
{chr(10).join([f'- {t}' for t in chunk_titles])}

ì´ì „ ì„¹ì…˜ ë‚´ìš©ê³¼ ë¬¸ë§¥ì´ ì´ì–´ì§€ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”.
=====================================================================
"""
        # ë©”ì‹œì§€ ë³µì‚¬ í›„ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        current_messages = copy.deepcopy(base_messages)
        # ê¸°ì¡´ ìœ ì € ë©”ì‹œì§€ì— ì²­í¬ ì§€ì‹œ ì¶”ê°€
        current_messages[-1]["content"] = base_user_content + chunk_instruction
        
        # LLM í˜¸ì¶œ
        result = llm.invoke(current_messages)
        result_dict = ensure_dict(result)
        
        # ê²°ê³¼ ë³‘í•©
        generated_sections = result_dict.get("sections", [])
        
        # ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ ë©”íƒ€ë°ì´í„°(Key Features ë“±) ê°€ì ¸ì˜¤ê¸°
        if i == 0:
            full_draft["title"] = result_dict.get("title", full_draft["title"])
            full_draft["key_features"] = result_dict.get("key_features", [])
            full_draft["executive_summary"] = result_dict.get("executive_summary", "")
            
        full_draft["sections"].extend(generated_sections)
        
        # (ì„ íƒ) ë‹¤ìŒ ì²­í¬ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, 
        # í˜„ì¬ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜ ì „ì²´ êµ¬ì¡°ë¥¼ LLMì´ ì•Œê³  ìˆìœ¼ë¯€ë¡œ ë„˜ì–´ê°.
        
    logger.info(f"[Writer Chunk] ë³‘í•© ì™„ë£Œ: ì´ {len(full_draft['sections'])}ê°œ ì„¹ì…˜")
    return full_draft

