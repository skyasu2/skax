"""
PlanCraft Agent - Writer Agent (ì‘ê°€)

ì‹¤ì§ˆì ì¸ ê¸°íšì„œ ë³¸ë¬¸ì„ ì‘ì„±í•˜ëŠ” í•µì‹¬ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
êµ¬ì¡°í™”ëœ ëª©ì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì„¹ì…˜ì— ë“¤ì–´ê°ˆ ë‚´ìš©ì„ ì±„ìš°ë©°, ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•©ë‹ˆë‹¤.

[Key Capabilities]
1. ì ì‘í˜• ì‘ì„± ì „ëµ (Adaptive Writing Strategy):
   - Fast: ì†ë„ë¥¼ ìœ„í•´ í•œ ë²ˆì— ì „ì²´ë¥¼ ì‘ì„±í•˜ëŠ” Single-shot ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
   - Balanced/Quality: ReAct íŒ¨í„´ìœ¼ë¡œ ë°ì´í„° ë¶€ì¡± ì‹œ ììœ¨ì ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
2. ReAct íŒ¨í„´ (Reasoning + Acting):
   - [Thought] ì‘ì„± ì¤‘ ë°ì´í„° ë¶€ì¡± íŒë‹¨
   - [Action] Specialist/Web/RAG ë„êµ¬ í˜¸ì¶œ
   - [Observation] ê²°ê³¼ í™•ì¸ í›„ ì‘ì„± ê³„ì†
3. ëŠ¥ë™ì  ë°ì´í„° í†µí•©:
   - RAG(Vector DB) ë° ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰(Active Search) ê²°ê³¼ë¥¼ ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ëƒ…ë‹ˆë‹¤.
   - Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë° ì‹œê° ìë£Œ ì½”ë“œë¥¼ ìƒì„±í•˜ì—¬ ë¬¸ì„œì˜ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.
"""
from langchain_core.messages import SystemMessage, HumanMessage
from utils.llm import get_llm
from utils.schemas import DraftResult
from utils.time_context import get_time_context, get_time_instruction
from graph.state import PlanCraftState, update_state, ensure_dict
from utils.settings import settings
from utils.file_logger import get_file_logger

# í—¬í¼ í•¨ìˆ˜ ì„í¬íŠ¸ (Refactored)
from agents.writer_helpers import (
    get_prompts_by_doc_type,
    execute_web_search,
    execute_specialist_agents,
    build_visual_instruction,
    build_visual_feedback,
    build_review_context,
    build_refinement_context,
    validate_draft
)


def run(state: PlanCraftState) -> PlanCraftState:
    """
    ì´ˆì•ˆ ì‘ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰

    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (structure í•„ìˆ˜)

    Returns:
        PlanCraftState: draft í•„ë“œê°€ ì¶”ê°€ëœ ìƒíƒœ
    """
    logger = get_file_logger()

    # 1. ì…ë ¥ ê²€ì¦
    user_input = state.get("user_input", "")
    structure = state.get("structure")
    if not structure:
        return update_state(state, error="êµ¬ì¡°í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2. ì„¤ì • ë¡œë“œ
    from utils.settings import get_preset
    active_preset = state.get("generation_preset", settings.active_preset)
    preset = get_preset(active_preset)
    refine_count = state.get("refine_count", 0)

    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í—¬í¼ í•¨ìˆ˜ ìœ„ì„)
    rag_context = state.get("rag_context", "")
    web_context = state.get("web_context", "")

    # ì›¹ ê²€ìƒ‰ ì‹¤í–‰ (Writer ìì²´ ê²€ìƒ‰ ì œê±° - Workflowì—ì„œ ì´ë¯¸ ìˆ˜í–‰ë¨)
    # web_context = execute_web_search(user_input, rag_context, web_context, logger)
    if not web_context:
        web_context = ""

    # ì „ë¬¸ ì—ì´ì „íŠ¸ ë¶„ì„
    specialist_context, state = execute_specialist_agents(
        state, user_input, web_context, refine_count, logger
    )

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt, user_prompt_template = get_prompts_by_doc_type(state)
    visual_instruction = build_visual_instruction(preset, logger)

    # User Constraints ì¶”ì¶œ
    user_constraints_str = "ì—†ìŒ"
    analysis_obj = state.get("analysis")
    if analysis_obj:
        u_constraints = analysis_obj.get("user_constraints", []) if isinstance(analysis_obj, dict) \
            else getattr(analysis_obj, "user_constraints", [])
        if u_constraints:
            user_constraints_str = "\n".join([f"- {c}" for c in u_constraints])

    # Web URLs í¬ë§·íŒ…
    web_urls = state.get("web_urls", [])
    web_urls_str = "\n".join([f"- {url}" for url in web_urls]) if web_urls else "ì—†ìŒ"

    try:
        formatted_prompt = user_prompt_template.format(
            user_input=user_input,
            structure=str(structure),
            web_context=web_context if web_context else "ì—†ìŒ",
            web_urls=web_urls_str,
            context=rag_context if rag_context else "ì—†ìŒ",
            visual_instruction=visual_instruction,
            user_constraints=user_constraints_str
        )
        
        # [NEW] Quality ëª¨ë“œ ì „ìš© ì¶”ê°€ ì§€ì¹¨ (ì–‘ì  í’ì„±í•¨ ê°•í™”)
        if preset.name == "quality":
            quality_instruction = """
\n=====================================================================
ğŸ‘‘ **[Quality Mode] ìµœê³  í’ˆì§ˆ ì‘ì„± ì§€ì¹¨**
1. **í•µì‹¬ ê¸°ëŠ¥(Key Features)**: ë°˜ë“œì‹œ **6ê°œ ì´ìƒ**ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ìƒì„¸íˆ ê¸°ìˆ í•˜ì„¸ìš”.
2. **ì„¹ì…˜ ë¶„ëŸ‰**: ê° ì„¹ì…˜ì€ ìµœì†Œ 500ì ì´ìƒ, ê¹Šì´ ìˆëŠ” ë‚´ìš©ì„ ë‹´ìœ¼ì„¸ìš”.
3. **ì°¸ê³  ìë£Œ**: ì¸ìš©ëœ ëª¨ë“  ì¶œì²˜ë¥¼ ë§ˆì§€ë§‰ì— 'ì°¸ê³  ìë£Œ' ì„¹ì…˜ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
=====================================================================\n
"""
            formatted_prompt += quality_instruction

    except KeyError as e:
        return update_state(state, error=f"í”„ë¡¬í”„íŠ¸ í¬ë§· ì˜¤ë¥˜: {str(e)}")

    # ì „ë¬¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ì£¼ì…
    if specialist_context:
        specialist_header = f"""
=====================================================================
ğŸ¤– ì „ë¬¸ ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼ (ë°˜ë“œì‹œ í™œìš©í•  ê²ƒ!)
=====================================================================
{specialist_context}
=====================================================================
"""
        formatted_prompt = specialist_header + formatted_prompt

    # Refinement ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    review_context = build_review_context(state, refine_count)
    refinement_context = build_refinement_context(refine_count, preset.min_sections)

    # Refinement Strategy
    strategy_msg = ""
    refinement_guideline = state.get("refinement_guideline")
    if refine_count > 0 and refinement_guideline:
        direction = refinement_guideline.get("overall_direction", "") if isinstance(refinement_guideline, dict) \
            else getattr(refinement_guideline, "overall_direction", "")
        guidelines = refinement_guideline.get("specific_guidelines", []) if isinstance(refinement_guideline, dict) \
            else getattr(refinement_guideline, "specific_guidelines", [])
        strategy_msg = f"ğŸš€ ë°©í–¥: {direction}\nì§€ì¹¨: {chr(10).join([f'- {g}' for g in guidelines])}\n"

    prepend_msg = strategy_msg + review_context + refinement_context
    formatted_prompt = prepend_msg + formatted_prompt + get_time_instruction()

    # 5. LLM í˜¸ì¶œ
    messages = [
        {"role": "system", "content": get_time_context() + system_prompt},
        {"role": "user", "content": formatted_prompt}
    ]

    # [NEW] ReAct ëª¨ë“œ íŒë‹¨ (Balanced/Qualityì—ì„œ í™œì„±í™”)
    # 1. í”„ë¦¬ì…‹ ì„¤ì • í™•ì¸ (enable_writer_react)
    # 2. state ì˜¤ë²„ë¼ì´ë“œ í™•ì¸ (UIì—ì„œ ê°œë³„ ë¹„í™œì„±í™” ê°€ëŠ¥)
    use_react_mode = (
        preset.enable_writer_react and                 # í”„ë¦¬ì…‹ì—ì„œ í™œì„±í™”ë¨
        refine_count == 0 and                          # ì²« ì‘ì„± ì‹œì—ë§Œ
        state.get("enable_writer_react", True)         # stateì—ì„œ ë¹„í™œì„±í™” ê°€ëŠ¥
    )

    if use_react_mode:
        logger.info(f"[Writer] ğŸ”„ ReAct ëª¨ë“œ í™œì„±í™” (preset={active_preset})")
        return _run_with_react_loop(
            state, messages, preset, specialist_context, logger
        )

    # Standard Mode (Fast ë˜ëŠ” ReAct ë¹„í™œì„±í™” ì‹œ)
    writer_llm = get_llm(
        model_type=preset.model_type,
        temperature=preset.temperature
    ).with_structured_output(DraftResult)

    max_retries = preset.writer_max_retries
    final_draft_dict = None
    last_draft_dict = None
    last_error = None

    # Quality ëª¨ë“œ + ReAct ë¹„í™œì„±í™” ì‹œ: ë¶„í•  ì‘ì„± (Chunk Writing)
    if active_preset == "quality" and structure and not use_react_mode:
        logger.info("[Writer] ğŸ‘‘ Quality Mode: Chunk Writing ì‹œì‘ (ì„¹ì…˜ë³„ ìƒì„¸ ì‘ì„±)")
        try:
            final_draft_dict = _write_in_chunks(
                writer_llm, 
                messages, 
                structure, 
                logger
            )
            # Chunk Writing ê²°ê³¼ëŠ” ì´ë¯¸ Qualityê°€ í™•ë³´ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³  loop break
            # ë‹¨, ê¸°ë³¸ì ì¸ í¬ë§· ê²€ì¦ì€ í•œ ë²ˆ ìˆ˜í–‰
            issues = validate_draft(final_draft_dict, preset, specialist_context, refine_count, logger)
            if issues:
                logger.warning(f"[Writer] Chunk Writing ê²€ì¦ ì´ìŠˆ(ë¬´ì‹œë¨): {issues}")
            
            return update_state(state, draft=final_draft_dict, current_step="write")
        except Exception as e:
            logger.error(f"[Writer] Chunk Writing ì‹¤íŒ¨: {e}, Fallback to Standard Mode")
            # ì‹¤íŒ¨ ì‹œ ì•„ë˜ í‘œì¤€ ëª¨ë“œë¡œ ì§„í–‰ (Fallback)

    # [Standard Mode] í†µìœ¼ë¡œ ì‘ì„± (Fast/Balanced or Quality Fallback)
    for current_try in range(max_retries):
        try:
            logger.info(f"[Writer] ì´ˆì•ˆ ì‘ì„± ì‹œë„ ({current_try + 1}/{max_retries})...")
            draft_result = writer_llm.invoke(messages)
            draft_dict = ensure_dict(draft_result)
            last_draft_dict = draft_dict

            # Self-Reflection ê²€ì¦ (í—¬í¼ í•¨ìˆ˜ ìœ„ì„)
            validation_issues = validate_draft(
                draft_dict, preset, specialist_context, refine_count, logger
            )

            if validation_issues:
                logger.warning(f"[Writer] ê²€ì¦ ì‹¤íŒ¨: {', '.join(validation_issues)}")

                # ì‹œê°ì  ìš”ì†Œ ëˆ„ë½ ì‹œ êµ¬ì²´ì ì¸ ì˜ˆì‹œ í”¼ë“œë°± ì¶”ê°€
                visual_feedback = build_visual_feedback(validation_issues, preset)
                base_feedback = f"[ê²€ì¦ ì‹¤íŒ¨] {', '.join(validation_issues)}. ëª¨ë“  ì„¹ì…˜ì„ ì™„ì „íˆ ì‘ì„±í•˜ì„¸ìš”."
                feedback = base_feedback + visual_feedback if visual_feedback else base_feedback

                messages.append({"role": "user", "content": feedback})
                last_error = f"ê²€ì¦ ì‹¤íŒ¨: {', '.join(validation_issues)}"
                continue

            # í†µê³¼
            final_draft_dict = draft_dict
            section_count = len(draft_dict.get("sections", []))
            logger.info(f"[Writer] âœ… Self-Check í†µê³¼ (ì„¹ì…˜ {section_count}ê°œ)")
            break

        except Exception as e:
            logger.error(f"[Writer Error] {e}")
            last_error = str(e)

    # 6. ê²°ê³¼ ë°˜í™˜
    if final_draft_dict:
        return update_state(state, draft=final_draft_dict, current_step="write")
    elif last_draft_dict:
        logger.warning("[Writer] âš ï¸ ë¶€ë¶„ ê²°ê³¼ ì‚¬ìš©")
        return update_state(state, draft=last_draft_dict, current_step="write")
    else:
        return update_state(state, error=f"Writer ì‹¤íŒ¨: {last_error}")


def _write_in_chunks(llm, base_messages, structure_obj, logger):
    """
    [Quality Mode ì „ìš©] ì„¹ì…˜ì„ ë‚˜ëˆ„ì–´ ì‘ì„±í•œ í›„ ë³‘í•©í•©ë‹ˆë‹¤.
    
    Args:
        llm: Writer LLM
        base_messages: ê¸°ë³¸ ì‹œìŠ¤í…œ/ìœ ì € ë©”ì‹œì§€
        structure_obj: Structurer ì¶œë ¥ ê°ì²´ (sections ë¦¬ìŠ¤íŠ¸ í¬í•¨)
        logger: ë¡œê±°
        
    Returns:
        dict: í•©ì³ì§„ DraftResult ë”•ì…”ë„ˆë¦¬
    """
    import copy
    from graph.state import ensure_dict

    structure_dict = ensure_dict(structure_obj)
    sections = structure_dict.get("sections", [])
    if not sections:
        raise ValueError("êµ¬ì¡°ì— ì„¹ì…˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    full_draft = {
        "title": structure_dict.get("title", "Business Plan"),
        "sections": [],
        "key_features": []  # ë‚˜ì¤‘ì— ì²« ì²­í¬ì—ì„œ ê°€ì ¸ì˜´
    }
    
    # ì²­í¬ ì‚¬ì´ì¦ˆ: 3ê°œ ì„¹ì…˜ì”©
    chunk_size = 3
    total_sections = len(sections)
    
    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸(base_messages[-1])ì—ì„œ ê¸°ë³¸ ì§€ì‹œì‚¬í•­ ì¶”ì¶œ
    base_user_content = base_messages[-1]["content"] if base_messages else ""
    
    for i in range(0, total_sections, chunk_size):
        chunk_sections = sections[i : i + chunk_size]
        chunk_titles = [s.get("title", s) if isinstance(s, dict) else str(s) for s in chunk_sections]
        
        logger.info(f"[Writer Chunk] ì„¹ì…˜ {i+1}~{min(i+chunk_size, total_sections)} ì‘ì„± ì¤‘: {chunk_titles}")
        
        chunk_instruction = f"""
\n=====================================================================
ğŸ§© **[Section Writing Phase {i//chunk_size + 1}]**
ì „ì²´ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšì„œ ì¤‘ ì•„ë˜ ì„¹ì…˜ë“¤ë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ì ˆëŒ€ ë‹¤ë¥¸ ì„¹ì…˜ì„ ê±´ë„ˆë›°ê±°ë‚˜ í•©ì¹˜ì§€ ë§ˆì„¸ìš”.

**ì‘ì„± ëŒ€ìƒ ì„¹ì…˜**:
{chr(10).join([f'- {t}' for t in chunk_titles])}

ì´ì „ ì„¹ì…˜ ë‚´ìš©ê³¼ ë¬¸ë§¥ì´ ì´ì–´ì§€ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”.
=====================================================================
"""
        # ë©”ì‹œì§€ ë³µì‚¬ í›„ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        current_messages = copy.deepcopy(base_messages)
        # ê¸°ì¡´ ìœ ì € ë©”ì‹œì§€ì— ì²­í¬ ì§€ì‹œ ì¶”ê°€
        current_messages[-1]["content"] = base_user_content + chunk_instruction
        
        # LLM í˜¸ì¶œ
        result = llm.invoke(current_messages)
        result_dict = ensure_dict(result)
        
        # ê²°ê³¼ ë³‘í•©
        generated_sections = result_dict.get("sections", [])
        
        # ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ ë©”íƒ€ë°ì´í„°(Key Features ë“±) ê°€ì ¸ì˜¤ê¸°
        if i == 0:
            full_draft["title"] = result_dict.get("title", full_draft["title"])
            full_draft["key_features"] = result_dict.get("key_features", [])
            full_draft["executive_summary"] = result_dict.get("executive_summary", "")
            
        full_draft["sections"].extend(generated_sections)
        
        # (ì„ íƒ) ë‹¤ìŒ ì²­í¬ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, 
        # í˜„ì¬ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜ ì „ì²´ êµ¬ì¡°ë¥¼ LLMì´ ì•Œê³  ìˆìœ¼ë¯€ë¡œ ë„˜ì–´ê°.
        
    logger.info(f"[Writer Chunk] ë³‘í•© ì™„ë£Œ: ì´ {len(full_draft['sections'])}ê°œ ì„¹ì…˜")
    return full_draft


# =============================================================================
# ReAct Pattern Implementation
# =============================================================================

# ReAct ì„¤ì •
REACT_MAX_TOOL_CALLS = 3  # ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜
REACT_MAX_ITERATIONS = 5  # ìµœëŒ€ ë£¨í”„ ë°˜ë³µ íšŸìˆ˜


def _run_with_react_loop(
    state: PlanCraftState,
    base_messages: list,
    preset,
    specialist_context: str,
    logger
) -> PlanCraftState:
    """
    ReAct íŒ¨í„´ìœ¼ë¡œ ì´ˆì•ˆ ì‘ì„± (Tool í˜¸ì¶œ ê°€ëŠ¥)

    Writerê°€ ì‘ì„± ì¤‘ ë°ì´í„° ë¶€ì¡±ì„ ììœ¨ì ìœ¼ë¡œ íŒë‹¨í•˜ê³ ,
    í•„ìš”ì‹œ Specialist/Web/RAG ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ ë³´ê°•í•©ë‹ˆë‹¤.

    Flow:
        [Thought] "ì‹œì¥ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹¤"
        [Action]  request_specialist_analysis("market", "TAM/SAM/SOM ë¶„ì„")
        [Observation] {tam: "10ì¡°ì›", ...}
        [Continue] ì‘ì„± ê³„ì†...
        [Final Answer] DraftResult JSON

    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        base_messages: ì‹œìŠ¤í…œ/ìœ ì € ë©”ì‹œì§€
        preset: í”„ë¦¬ì…‹ ì„¤ì •
        specialist_context: ê¸°ì¡´ Specialist ë¶„ì„ ê²°ê³¼
        logger: ë¡œê±°

    Returns:
        PlanCraftState: draft í•„ë“œê°€ ì¶”ê°€ëœ ìƒíƒœ
    """
    from langchain_core.messages import AIMessage, ToolMessage
    from tools.writer_tools import get_writer_tools
    from prompts.writer_prompt import WRITER_REACT_INSTRUCTION

    logger.info("[Writer ReAct] ReAct ë£¨í”„ ì‹œì‘")

    # 1. ë„êµ¬ ì¤€ë¹„
    tools = get_writer_tools()
    tool_map = {tool.name: tool for tool in tools}

    # 2. LLM with Tools ì„¤ì •
    llm = get_llm(
        model_type=preset.model_type,
        temperature=preset.temperature
    )
    llm_with_tools = llm.bind_tools(tools)

    # 3. ReAct ì§€ì¹¨ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    messages = base_messages.copy()
    messages[0]["content"] += "\n\n" + WRITER_REACT_INSTRUCTION

    # 4. ReAct ë£¨í”„
    tool_call_count = 0
    iteration = 0
    tool_results_context = []  # ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ëˆ„ì 

    while iteration < REACT_MAX_ITERATIONS:
        iteration += 1
        logger.info(f"[Writer ReAct] Iteration {iteration}/{REACT_MAX_ITERATIONS}")

        try:
            response = llm_with_tools.invoke(messages)

            # Tool í˜¸ì¶œ ê°ì§€
            if hasattr(response, 'tool_calls') and response.tool_calls:
                # AIMessage ì¶”ê°€
                messages.append(response)

                for tool_call in response.tool_calls:
                    if tool_call_count >= REACT_MAX_TOOL_CALLS:
                        logger.warning(f"[Writer ReAct] ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ ë„ë‹¬ ({REACT_MAX_TOOL_CALLS})")
                        # ë” ì´ìƒ ë„êµ¬ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¢…ë£Œ
                        messages.append(ToolMessage(
                            content="[LIMIT] ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ì˜ ì •ë³´ë¡œ ì‘ì„±ì„ ì™„ë£Œí•˜ì„¸ìš”.",
                            tool_call_id=tool_call['id']
                        ))
                        break

                    tool_name = tool_call['name']
                    tool_args = tool_call['args']

                    logger.info(f"[Writer ReAct] Tool í˜¸ì¶œ: {tool_name}({list(tool_args.keys())})")

                    # Tool ì‹¤í–‰
                    result = _execute_react_tool(tool_name, tool_args, tool_map, logger)
                    tool_call_count += 1

                    # ê²°ê³¼ ì €ì¥
                    tool_results_context.append({
                        "tool": tool_name,
                        "query": tool_args.get("query", tool_args.get("specialist_type", "")),
                        "result_preview": result[:200] + "..." if len(result) > 200 else result
                    })

                    # ToolMessage ì¶”ê°€
                    messages.append(ToolMessage(
                        content=result,
                        tool_call_id=tool_call['id']
                    ))

                # ë„êµ¬ í˜¸ì¶œ í›„ ë£¨í”„ ê³„ì†
                continue

            else:
                # Tool í˜¸ì¶œ ì—†ìŒ = ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ
                logger.info("[Writer ReAct] Tool í˜¸ì¶œ ì™„ë£Œ, ìµœì¢… ì‘ì„± ë‹¨ê³„ë¡œ ì§„ì…")
                break

        except Exception as e:
            logger.error(f"[Writer ReAct] ë£¨í”„ ì˜¤ë¥˜: {e}")
            break

    # 5. ìµœì¢… Structured Output ìƒì„±
    logger.info("[Writer ReAct] ìµœì¢… DraftResult ìƒì„± ì¤‘...")

    # ë„êµ¬ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
    if tool_results_context:
        tools_summary = "\n\n".join([
            f"### {tr['tool']} ê²°ê³¼ ({tr['query']})\n{tr['result_preview']}"
            for tr in tool_results_context
        ])
        additional_context = f"""
=====================================================================
ğŸ”§ ReAct ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ (ë°˜ë“œì‹œ í™œìš©í•  ê²ƒ!)
=====================================================================
{tools_summary}
=====================================================================
"""
        # ìœ ì € ë©”ì‹œì§€ì— ì¶”ê°€
        messages[-1] = {"role": "user", "content": messages[1]["content"] + additional_context}

    # Structured Output LLMìœ¼ë¡œ ìµœì¢… ì‘ì„±
    final_llm = get_llm(
        model_type=preset.model_type,
        temperature=preset.temperature
    ).with_structured_output(DraftResult)

    try:
        # ìµœì¢… ë©”ì‹œì§€ ì •ë¦¬ (Tool ê´€ë ¨ ë©”ì‹œì§€ ì œê±°í•˜ê³  ì»¨í…ìŠ¤íŠ¸ë§Œ ìœ ì§€)
        final_messages = [
            messages[0],  # System
            {"role": "user", "content": messages[1]["content"]}  # User (ì›ë³¸)
        ]

        # ë„êµ¬ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if tool_results_context:
            tools_context = "\n".join([
                f"- {tr['tool']}: {tr['result_preview']}"
                for tr in tool_results_context
            ])
            final_messages[1]["content"] += f"\n\n[ì¶”ê°€ ë°ì´í„° - ReAct ë„êµ¬ ê²°ê³¼]\n{tools_context}"

        final_result = final_llm.invoke(final_messages)
        draft_dict = ensure_dict(final_result)

        section_count = len(draft_dict.get("sections", []))
        logger.info(f"[Writer ReAct] âœ… ì‘ì„± ì™„ë£Œ (ì„¹ì…˜ {section_count}ê°œ, ë„êµ¬ í˜¸ì¶œ {tool_call_count}íšŒ)")

        return update_state(state, draft=draft_dict, current_step="write")

    except Exception as e:
        logger.error(f"[Writer ReAct] ìµœì¢… ì‘ì„± ì‹¤íŒ¨: {e}")
        return update_state(state, error=f"Writer ReAct ì‹¤íŒ¨: {str(e)}")


def _execute_react_tool(
    tool_name: str,
    tool_args: dict,
    tool_map: dict,
    logger
) -> str:
    """
    ReAct ë„êµ¬ ì‹¤í–‰ í—¬í¼

    Args:
        tool_name: ë„êµ¬ ì´ë¦„
        tool_args: ë„êµ¬ ì¸ì
        tool_map: ë„êµ¬ ì´ë¦„ â†’ ë„êµ¬ ê°ì²´ ë§µ
        logger: ë¡œê±°

    Returns:
        ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë¬¸ìì—´
    """
    if tool_name not in tool_map:
        return f"[ERROR] ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}. ì‚¬ìš© ê°€ëŠ¥: {list(tool_map.keys())}"

    tool = tool_map[tool_name]

    try:
        result = tool.invoke(tool_args)
        logger.info(f"[Writer ReAct] Tool '{tool_name}' ì„±ê³µ: {len(result)}ì")
        return result
    except Exception as e:
        logger.error(f"[Writer ReAct] Tool '{tool_name}' ì‹¤íŒ¨: {e}")
        return f"[ERROR] {tool_name} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}. ê°€ì •ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”."

