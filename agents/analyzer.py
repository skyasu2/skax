"""
PlanCraft Agent - Analyzer Agent (ë¶„ì„ê°€)

ì‚¬ìš©ìì˜ ì´ˆê¸° ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ê¸°íšì˜ ë°©í–¥ì„±(Topic, Purpose)ì„ ì„¤ì •í•˜ê³ ,
í•„ìˆ˜ì ì¸ í•µì‹¬ ê¸°ëŠ¥(Key Features)ê³¼ ì œì•½ì‚¬í•­(Constraints)ì„ ë„ì¶œí•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

[Key Capabilities]
1. ëª¨ë“œë³„ ê¸°ëŠ¥ ì œì–´:
   - GenerationPresetì— ë”°ë¼ ìµœì†Œ í•µì‹¬ ê¸°ëŠ¥ ê°œìˆ˜(min_key_features)ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
   - Fast(3ê°œ) / Balanced(5ê°œ) / Quality(7ê°œ)
2. HITL (Human-in-the-Loop) ìƒí˜¸ì‘ìš©:
   - ì…ë ¥ì´ ë¹ˆì•½í•  ê²½ìš°(Situation B) ì‚¬ìš©ìì˜ ìŠ¹ì¸ì„ ì–»ê¸° ìœ„í•œ ì œì•ˆ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.
   - ì…ë ¥ì´ êµ¬ì²´ì ì¼ ê²½ìš°(Situation C) ë°”ë¡œ êµ¬ì¡°í™” ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ëŠ” Fast Trackì„ ì§€ì›í•©ë‹ˆë‹¤.
"""
from datetime import datetime
from langchain_core.messages import SystemMessage, HumanMessage
from utils.llm import get_llm
from utils.schemas import AnalysisResult
from utils.time_context import get_time_context, get_time_instruction
from graph.state import PlanCraftState, update_state, ensure_dict
from prompts.analyzer_prompt import ANALYZER_SYSTEM_PROMPT, ANALYZER_USER_PROMPT
from utils.file_logger import get_file_logger

# LLMì€ í•¨ìˆ˜ ë‚´ì—ì„œ ë™ì  ì´ˆê¸°í™” (ì„¤ì • ìœ ì—°ì„±)


def _set_hitl_options(analysis_dict: dict, user_input: str, clarification_questions: list) -> None:
    """
    HITL ì˜µì…˜ ì„¤ì • í—¬í¼ í•¨ìˆ˜

    ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ì˜µì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    topic = analysis_dict.get("topic", user_input)
    questions_text = "\n".join(f"â€¢ {q}" for q in clarification_questions) if clarification_questions else ""

    if questions_text:
        analysis_dict["option_question"] = f"ğŸ’¡ '{topic}' ê¸°íšì„ ìœ„í•´ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\n{questions_text}"
    else:
        analysis_dict["option_question"] = f"ğŸ’¡ '{topic}' ê¸°íšì„ ì´ë ‡ê²Œ ì§„í–‰í• ê¹Œìš”?"

    analysis_dict["options"] = [
        {"id": "yes", "title": "ë„¤, ì§„í–‰í•©ë‹ˆë‹¤", "description": "AIê°€ í•©ë¦¬ì ì¸ ê°€ì •ìœ¼ë¡œ ê¸°íšì„œ ìƒì„±"},
        {"id": "retry", "title": "ìˆ˜ì •í• ê²Œìš”", "description": "ì¶”ê°€ ì •ë³´ ì…ë ¥ í›„ ì§„í–‰"}
    ]


def _get_analyzer_llm(temperature: float = None):
    """
    Analyzer LLM ìƒì„± (ë™ì  ì„¤ì •)
    
    Args:
        temperature: ìƒì„± ì˜¨ë„ (Noneì´ë©´ ê¸°ë³¸ê°’ 0.7)
    """
    # ì „ì—­ ìºì‹± ì œê±° -> í”„ë¦¬ì…‹ ë³€ê²½ì— ì¦‰ì‹œ ëŒ€ì‘
    # with_structured_outputì€ í˜¸ì¶œ ì‹œë§ˆë‹¤ íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•˜ë¯€ë¡œ
    # ë„ˆë¬´ ë¹ˆë²ˆí•œ í˜¸ì¶œì´ ë¶€ë‹´ëœë‹¤ë©´ settings ê°ì²´ ë‚´ì— LRU ìºì‹±ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŒ.
    # í•˜ì§€ë§Œ í˜„ì¬ íŠ¸ë˜í”½ ìˆ˜ì¤€ì—ì„œëŠ” ë§¤ë²ˆ ìƒì„±í•´ë„ ë¬´ë°©í•¨.
    
    # settings.LLM_TEMPERATURE_CREATIVE ê¸°ë³¸ê°’ í™œìš©
    from utils.settings import settings
    temp = temperature if temperature is not None else settings.LLM_TEMPERATURE_CREATIVE
    
    return get_llm(temperature=temp).with_structured_output(AnalysisResult)

def run(state: PlanCraftState) -> PlanCraftState:
    """
    ìš”ì²­ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹¤í–‰

    ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ê¸°íšì˜ ì£¼ì œ, ëª©ì , ì£¼ìš” ê¸°ëŠ¥ ë“±ì„ êµ¬ì¡°í™”ëœ ë°ì´í„°(AnalysisResult)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        state: user_input, file_content ë“±ì„ í¬í•¨í•œ ìƒíƒœ

    Returns:
        Updated state with 'analysis' field

    Example:
        >>> state = {"user_input": "AI í—¬ìŠ¤ì¼€ì–´ ì•± ê¸°íší•´ì¤˜"}
        >>> result = run(state)
        >>> print(result["analysis"]["topic"])
        'AI í—¬ìŠ¤ì¼€ì–´ ì•±'
    """
    # 1. ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (Dict Access)
    user_input = state.get("user_input", "")
    rag_context = state.get("rag_context", "")
    web_context = state.get("web_context", "")
    previous_plan = state.get("previous_plan")
    
    # [FILE] íŒŒì¼ ë‚´ìš© í†µí•© (ê¸¸ì´ ì œí•œ ì ìš©)
    from utils.settings import settings
    MAX_FILE_LENGTH = settings.MAX_FILE_LENGTH
    
    file_content = state.get("file_content")
    file_context_msg = ""
    
    if file_content:
        # ê¸¸ì´ ì œí•œ (í† í° ë¹„ìš© ë° ì»¨í…ìŠ¤íŠ¸ ì´ˆê³¼ ë°©ì§€)
        if len(file_content) > MAX_FILE_LENGTH:
            file_content = file_content[:MAX_FILE_LENGTH] + "\n...(ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ìƒëµë¨)..."
            get_file_logger().info(f"[Analyzer] íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ {MAX_FILE_LENGTH}ìë¡œ ë‹¨ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        file_context_msg = f"\n\n=== [ì²¨ë¶€ íŒŒì¼ ë‚´ìš© (ì¤‘ìš”)] ===\n{file_content}\n=============================\n"
        
        # ì‚¬ìš©ì ì…ë ¥ì´ ë§¤ìš° ì§§ìœ¼ë©´ íŒŒì¼ ë‚´ìš©ì´ ì£¼ê°€ ë¨ì„ ì•Œë¦¼
        if len(user_input.strip()) < 10:
            get_file_logger().info("[Analyzer] ì‚¬ìš©ì ì…ë ¥ì´ ì§§ì•„ ì²¨ë¶€ íŒŒì¼ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")

    # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    review_data = state.get("review")
    current_analysis = state.get("analysis") # [NEW] í˜„ì¬ ë¶„ì„ ìƒíƒœ (ì»¨íŒìš©)

    if current_analysis:
        # ì´ë¯¸ ë¶„ì„ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´ í¬ë§·íŒ… (JSON String)
        import json
        current_analysis_str = json.dumps(current_analysis, ensure_ascii=False, indent=2)
    else:
        current_analysis_str = "ì—†ìŒ"

    review_context = "ì—†ìŒ"
    if review_data:
        # review_data í˜•ì‹: {"overall_score": int, "feedback_summary": str, "verdict": str}
        feedback_summary = review_data.get("feedback_summary", "êµ¬ì²´ì  í”¼ë“œë°± ì—†ìŒ")
        score = review_data.get("overall_score", 0)
        review_context = (
            f"=== ğŸš¨ ì´ì „ ë²„ì „ì— ëŒ€í•œ ê¸´ê¸‰ í”¼ë“œë°± (í•„ìˆ˜ ë°˜ì˜) ===\n"
            f"í‰ê°€ ì ìˆ˜: {score}ì \n"
            f"ì§€ì  ì‚¬í•­: {feedback_summary}\n"
            f"ì§€ì‹œ: ë¶„ì„ ë‹¨ê³„ì—ì„œë¶€í„° ìœ„ ì§€ì  ì‚¬í•­ì„ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”."
        )
    
    context_parts = []
    if file_context_msg:
        # íŒŒì¼ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ ìµœìƒë‹¨ì— ë°°ì¹˜
        context_parts.append(file_context_msg)
        
    if web_context:
        context_parts.append(f"[ì›¹ì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´]\n{web_context}")
    if rag_context:
        context_parts.append(f"[ê¸°íšì„œ ì‘ì„± ê°€ì´ë“œ]\n{rag_context}")
    context = "\n\n".join(context_parts) if context_parts else "ì—†ìŒ"
    
    # [Logic] í”„ë¦¬ì…‹ ë¡œë”© (í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° LLM ì„¤ì •ìš©)
    from utils.settings import get_preset, settings
    active_preset = state.get("generation_preset", settings.active_preset)
    preset_config = get_preset(active_preset)

    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ì£¼ì… + ë™ì  ì„¤ì • ì ìš©)
    # min_key_featuresë¥¼ í”„ë¡¬í”„íŠ¸ì— ì£¼ì… (f-string ì‚¬ìš© ì‹œ JSON ì¤‘ê´„í˜¸ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ replace ì‚¬ìš©)
    system_msg_content = get_time_context() + ANALYZER_SYSTEM_PROMPT.replace(
        "{min_key_features}", str(preset_config.min_key_features)
    )

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ {review_data}, {current_analysis} ì¸ì ì „ë‹¬
    user_msg_content = ANALYZER_USER_PROMPT.format(
        user_input=user_input,
        previous_plan=previous_plan if previous_plan else "ì—†ìŒ",
        context=context,
        review_data=review_context,
        current_analysis=current_analysis_str
    ) + get_time_instruction()


    messages = [
        {"role": "system", "content": system_msg_content},
        {"role": "user", "content": user_msg_content}
    ]
    
    # 4. LLM í˜¸ì¶œ
    try:
        # LLM ìƒì„± ë° ì‹¤í–‰
        # AnalyzerëŠ” ì°½ì˜ì ì¸ ì‘ì—…ì´ë¯€ë¡œ preset temperature ì‚¬ìš© (default: creative)
        temperature = preset_config.temperature
        analyzer = _get_analyzer_llm(temperature=temperature)
        analysis_result = analyzer.invoke(messages)
        
        # 5. ìƒíƒœ ì—…ë°ì´íŠ¸ (Pydantic -> Dict ì¼ê´€ì„± ë³´ì¥)
        analysis_dict = ensure_dict(analysis_result)

        # [NOTE] í‚¤ì›Œë“œ ê¸°ë°˜ is_general_query ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ì€ Smart Routerë¡œ ì´ì „ë¨
        # Smart Routerê°€ intent ë¶„ë¥˜ë¥¼ ë‹´ë‹¹í•˜ë¯€ë¡œ, AnalyzerëŠ” LLM ê²°ê³¼ë¥¼ ì‹ ë¢°í•©ë‹ˆë‹¤.
        # Routerê°€ planningìœ¼ë¡œ íŒë‹¨í•œ ê²½ìš°ì—ë§Œ Analyzerê°€ í˜¸ì¶œë©ë‹ˆë‹¤.

        # [DEBUG] ë¶„ì„ ê²°ê³¼ ë¡œê¹…
        intent = state.get("intent", "unknown")
        get_file_logger().info(
            f"[Analyzer] LLM ë¶„ì„ ì™„ë£Œ: topic='{analysis_dict.get('topic')}', "
            f"is_general={analysis_dict.get('is_general_query')}, "
            f"need_info={analysis_dict.get('need_more_info')}, "
            f"router_intent={intent}"
        )

        # =============================================================================
        # 2-Tier Gate System: Source Gate â†’ Ambiguity Gate
        # =============================================================================
        #
        # [Source Gate] (Primary Decision)
        # - í…œí”Œë¦¿ ì‹¤í–‰ (is_template_execution=True) â†’ AutoPlan ê¸°ë³¸ (HITL ìŠ¤í‚µ)
        # - ì§ì ‘ ì…ë ¥ (is_template_execution=False) â†’ NeedInfo ê¸°ë³¸ (HITL í•„ìš”)
        #
        # [Ambiguity Gate] (Exception Handling)
        # - ì§ì ‘ ì…ë ¥ + ìŠ¬ë¡¯ ì™„ì „(0-1ê°œ ëˆ„ë½) â†’ AutoPlan (ì˜ˆì™¸ì  ìŠ¤í‚µ)
        # - í…œí”Œë¦¿ + ìŠ¬ë¡¯ 2ê°œ+ ëˆ„ë½ â†’ NeedInfo (ì˜ˆì™¸ì  HITL)
        # =============================================================================

        is_general = analysis_dict.get("is_general_query", False)
        missing_slots = analysis_dict.get("missing_slots", [])
        clarification_questions = analysis_dict.get("clarification_questions", [])
        is_template = state.get("is_template_execution", False)

        # [FALLBACK] LLMì´ missing_slotsë¥¼ ì œê³µí•˜ì§€ ì•Šì€ ê²½ìš° ì½”ë“œì—ì„œ ìì²´ ê²€ì‚¬
        intent_slots = analysis_dict.get("intent_slots")
        if not missing_slots and not is_general:
            detected_missing = []

            if intent_slots and isinstance(intent_slots, dict):
                if not intent_slots.get("target"):
                    detected_missing.append("target")
                if not intent_slots.get("purpose"):
                    detected_missing.append("purpose")
                if not intent_slots.get("output_type"):
                    detected_missing.append("output_type")
            else:
                input_lower = user_input.lower().strip()
                output_keywords = ["ì•±", "ì›¹", "ì‚¬ì´íŠ¸", "í”Œë«í¼", "ì„œë¹„ìŠ¤", "ì‹œìŠ¤í…œ", "ì–´í”Œ"]
                has_output_type = any(kw in input_lower for kw in output_keywords)
                detected_missing.append("target")
                if not has_output_type:
                    detected_missing.append("output_type")

            if detected_missing:
                missing_slots = detected_missing
                analysis_dict["missing_slots"] = missing_slots
                get_file_logger().info(f"[Fallback] ì½”ë“œì—ì„œ ìŠ¬ë¡¯ ê²€ì‚¬: missing_slots={missing_slots}")

        # [GUARDRAIL] ì¡ë‹´ ì˜¤ë¶„ë¥˜ ë³´ì •
        SERVICE_KEYWORDS = ["ë¦¬ë·°", "ì¶”ì²œ", "ì•±", "í”Œë«í¼", "ê¸°íš", "ê°œë°œ", "ì•„ì´ë””ì–´", "ì°½ì—…", "ì‚¬ì´íŠ¸", "ì›¹", "ì‹œìŠ¤í…œ", "ì„œë¹„ìŠ¤", "ë¶„ì„"]
        input_lower = user_input.lower().strip()

        if is_general and any(kw in input_lower for kw in SERVICE_KEYWORDS):
            get_file_logger().info(f"[Guardrail] ì¡ë‹´ ì˜¤ë¶„ë¥˜ ê°ì§€ë¨. ê¸°íš ëª¨ë“œë¡œ ê°•ì œ ì „í™˜.")
            is_general = False
            analysis_dict["is_general_query"] = False
            analysis_dict["topic"] = analysis_dict.get("topic") if analysis_dict.get("topic") != "ì¡ë‹´" else f"{user_input} ì„œë¹„ìŠ¤"

            if not missing_slots:
                missing_slots = ["target", "output_type"]
                analysis_dict["missing_slots"] = missing_slots
                analysis_dict["clarification_questions"] = [
                    "ì–´ë–¤ ì‚¬ìš©ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ì‹œë‚˜ìš”?",
                    "ì•±, ì›¹, ì„œë¹„ìŠ¤ ì¤‘ ì–´ë–¤ í˜•íƒœë¡œ ë§Œë“¤ê¹Œìš”?"
                ]

        # =============================================================================
        # 2-Tier Gate Logic
        # =============================================================================
        num_missing = len(missing_slots)

        if is_general:
            # ì¡ë‹´ì€ HITL ë¶ˆí•„ìš”
            analysis_dict["need_more_info"] = False
            get_file_logger().info("[Gate] ì¡ë‹´ â†’ AutoPlan (HITL ë¶ˆí•„ìš”)")

        elif is_template:
            # [Source Gate] í…œí”Œë¦¿ ì‹¤í–‰ â†’ ê¸°ë³¸ì ìœ¼ë¡œ AutoPlan
            if num_missing >= 2:
                # [Ambiguity Gate] ì˜ˆì™¸: í•„ìˆ˜ ìŠ¬ë¡¯ 2ê°œ+ ëˆ„ë½ ì‹œ HITL
                get_file_logger().info(f"[Gate] í…œí”Œë¦¿ + ìŠ¬ë¡¯ {num_missing}ê°œ ëˆ„ë½ â†’ NeedInfo (ì˜ˆì™¸)")
                analysis_dict["need_more_info"] = True
                _set_hitl_options(analysis_dict, user_input, clarification_questions)
            else:
                # í…œí”Œë¦¿ + ìŠ¬ë¡¯ ì¶©ë¶„ â†’ AutoPlan
                get_file_logger().info(f"[Gate] í…œí”Œë¦¿ + ìŠ¬ë¡¯ ì¶©ë¶„ â†’ AutoPlan")
                analysis_dict["need_more_info"] = False
                analysis_dict["option_question"] = None
                analysis_dict["options"] = []

        else:
            # [Source Gate] ì§ì ‘ ì…ë ¥ â†’ ê¸°ë³¸ì ìœ¼ë¡œ NeedInfo (HITL í•„ìš”)
            if num_missing <= 1:
                # [Ambiguity Gate] ì˜ˆì™¸: ìŠ¬ë¡¯ì´ ì¶©ë¶„í•˜ë©´ AutoPlan í—ˆìš©
                get_file_logger().info(f"[Gate] ì§ì ‘ì…ë ¥ + ìŠ¬ë¡¯ ì¶©ë¶„(ëˆ„ë½ {num_missing}ê°œ) â†’ AutoPlan (ì˜ˆì™¸)")
                analysis_dict["need_more_info"] = False
                analysis_dict["option_question"] = None
                analysis_dict["options"] = []
            else:
                # ì§ì ‘ ì…ë ¥ + ìŠ¬ë¡¯ ë¶€ì¡± â†’ NeedInfo (ê¸°ë³¸ ë™ì‘)
                get_file_logger().info(f"[Gate] ì§ì ‘ì…ë ¥ + ìŠ¬ë¡¯ {num_missing}ê°œ ëˆ„ë½ â†’ NeedInfo (ê¸°ë³¸)")
                analysis_dict["need_more_info"] = True
                _set_hitl_options(analysis_dict, user_input, clarification_questions)

        # LLMì´ ëª…ì‹œì ìœ¼ë¡œ ì˜µì…˜ì„ ì œê³µí•œ ê²½ìš° HITL í™œì„±í™”
        opts = analysis_dict.get("options", [])
        if opts and len(opts) > 0:
            analysis_dict["need_more_info"] = True
            analysis_dict["is_general_query"] = False

        updates = {
            "analysis": analysis_dict,
            "need_more_info": analysis_dict.get("need_more_info", False),
            "options": analysis_dict.get("options", []),
            "option_question": analysis_dict.get("option_question"),
            "current_step": "analyze",
            # [CRITICAL] ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘ ì‹œ ì´ì „ ê²°ê³¼ë¬¼(Stale State) ì´ˆê¸°í™”
            "final_output": None,
            "generated_plan": None
        }
            
        return update_state(state, **updates)
        
    except Exception as e:
        get_file_logger().error(f"[Analyzer] Failed: {e}")
        # Fallback: ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜ (ìš´ì˜ ì•ˆì „ì„± í™•ë³´)
        fallback_analysis = {
            "topic": "ë¶„ì„ ì‹¤íŒ¨ (ì‹œìŠ¤í…œ ì—ëŸ¬)",
            "purpose": "ì—ëŸ¬ ë°œìƒìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ê°’ ìƒì„±",
            "target_users": "ì•Œ ìˆ˜ ì—†ìŒ",
            "needs": [],
            "key_features": ["ê¸°ë³¸ ê¸°ëŠ¥ (ì—ëŸ¬ ë³µêµ¬ ëª¨ë“œ)"],
            "is_general_query": False,
            "need_more_info": False,
            "general_answer": None
        }
        return update_state(state, analysis=fallback_analysis, error=f"Analyzer Error: {str(e)}")
