"""
Utility Nodes for PlanCraft

[Chat Response Node]
LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ë¸Œë ˆì¸ìŠ¤í† ë°í•˜ë©° ì•„ì´ë””ì–´ë¥¼ ë°œì „ì‹œí‚¤ê³ ,
ì ì ˆí•œ ì‹œì ì— ê¸°íšì„œ ì‘ì„±ì„ ì œì•ˆí•©ë‹ˆë‹¤.
"""
from graph.state import PlanCraftState, update_state
from graph.nodes.common import update_step_history
from utils.file_logger import get_file_logger


# =============================================================================
# Chat Response ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# =============================================================================

CHAT_SYSTEM_PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ PlanCraftì˜ ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì˜¤ëŠ˜ ë‚ ì§œ]
{today_date}

[ë‹¹ì‹ ì— ëŒ€í•´]
- PlanCraft ê¸°íš ë„ìš°ë¯¸ (GPT-4 ê¸°ë°˜)
- ëª¨ë¥´ëŠ” ê²ƒì€ ëª¨ë¥¸ë‹¤ê³  ì†”ì§íˆ ë§í•˜ì„¸ìš”
- ìì‹ ì˜ ëª¨ë¸ì´ë‚˜ ë²„ì „ì— ëŒ€í•´ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”

[ì—­í• ]
- ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©° ì•„ì´ë””ì–´ë¥¼ í•¨ê»˜ ë°œì „ì‹œí‚µë‹ˆë‹¤
- ë¸Œë ˆì¸ìŠ¤í† ë°ì„ ë„ì™€ì£¼ê³ , ì§ˆë¬¸ì„ í†µí•´ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•©ë‹ˆë‹¤
- ì ì ˆí•œ ì‹œì ì— "ê¸°íšì„œë¥¼ ì‘ì„±í•´ ë“œë¦´ê¹Œìš”?"ë¼ê³  ì œì•ˆí•©ë‹ˆë‹¤

[ëŒ€í™” ìŠ¤íƒ€ì¼]
- ì¹œê·¼í•˜ê³  ê³µê°í•˜ëŠ” í†¤ (ë°˜ë§ë„ OK)
- ì§§ê³  í•µì‹¬ì ì¸ ì‘ë‹µ (2-4ë¬¸ì¥)
- ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ê³¼í•˜ì§€ ì•Šê²Œ)
- ì‚¬ìš©ì ì•„ì´ë””ì–´ì— ëŒ€í•œ ê¸ì •ì  í”¼ë“œë°±

[ê¸°íšì„œ ì œì•ˆ ì¡°ê±´]
ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ ê¸°íšì„œ ì‘ì„±ì„ ì œì•ˆí•˜ì„¸ìš”:
- êµ¬ì²´ì ì¸ ì„œë¹„ìŠ¤/ì•±/ì‚¬ì—… ì•„ì´ë””ì–´ê°€ ì–¸ê¸‰ë¨
- ì‚¬ìš©ìê°€ "ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?" ë¥˜ì˜ ì§ˆë¬¸ì„ í•¨
- ëŒ€í™”ê°€ 2-3íšŒ ì´ìƒ ì§„í–‰ë˜ì–´ ì•„ì´ë””ì–´ê°€ ì–´ëŠ ì •ë„ êµ¬ì²´í™”ë¨

[ì œì•ˆ ì˜ˆì‹œ]
"ì˜¤, ì¢‹ì€ ì•„ì´ë””ì–´ë„¤ìš”! ğŸ¯ ì´ ë‚´ìš©ìœ¼ë¡œ ê¸°íšì„œë¥¼ ì‘ì„±í•´ ë“œë¦´ê¹Œìš”?"
"êµ¬ì²´ì ì¸ ë°©í–¥ì´ ì¡íŒ ê²ƒ ê°™ì•„ìš”. ë³¸ê²©ì ìœ¼ë¡œ ê¸°íšì„œë¡œ ì •ë¦¬í•´ë³¼ê¹Œìš”?"

[ì£¼ì˜ì‚¬í•­]
- ê¸°íšì„œ ì‘ì„± ìš”ì²­ì´ ì•„ë‹Œ ì¼ë°˜ ëŒ€í™”ì—ë§Œ ì´ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
- ë„ˆë¬´ ê¸¸ê²Œ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ìê°€ ì•„ì§ íƒìƒ‰ ì¤‘ì´ë©´ ê°•ìš”í•˜ì§€ ë§ˆì„¸ìš”"""


# ì¸ì‚¬ ì‘ë‹µ í…œí”Œë¦¿ (í´ë°±ìš©)
GREETING_RESPONSES = {
    "default": "ì•ˆë…•í•˜ì„¸ìš”! PlanCraftì…ë‹ˆë‹¤. ğŸ¯\n\nì–´ë–¤ ì•±/ì„œë¹„ìŠ¤/ì‚¬ì—…ì„ ê¸°íší•´ ë“œë¦´ê¹Œìš”?\nì˜ˆì‹œ: \"ë°°ë‹¬ ì•±\", \"ë…ì„œ ëª¨ì„ í”Œë«í¼\", \"ì¹´í˜ ì°½ì—…\"",
    "help": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\nì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°íšì„œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆì–´ìš”:\nâ€¢ ì›¹/ì•± ì„œë¹„ìŠ¤ ê¸°íšì„œ\nâ€¢ ì‚¬ì—… ê³„íšì„œ\nâ€¢ í”Œë«í¼ êµ¬ì¶• ê¸°íšì„œ\n\nì•„ì´ë””ì–´ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”!",
    "thanks": "ì²œë§Œì—ìš”! ë‹¤ë¥¸ ê¸°íšì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š"
}


def general_response_node(state: PlanCraftState) -> PlanCraftState:
    """
    ì¼ë°˜ ì§ˆì˜ ì‘ë‹µ ë…¸ë“œ

    [í˜¸ì¶œ ê²½ë¡œ]
    1. Router â†’ greeting_response (intent=greeting): ì¸ì‚¬/ì¡ë‹´
    2. Analyzer â†’ general_response (is_general_query=True): Analyzer íŒë‹¨ ì¡ë‹´

    analysisê°€ ìˆìœ¼ë©´ general_answer ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ì¸ì‚¬ ì‘ë‹µ.
    """
    user_input = state.get("user_input", "").lower()
    intent = state.get("intent")
    analysis = state.get("analysis")

    # ì‘ë‹µ ê²°ì • ìš°ì„ ìˆœìœ„:
    # 1. analysis.general_answer (Analyzerê°€ ìƒì„±í•œ ì‘ë‹µ)
    # 2. intent ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ (Router ê²½ë¡œ)
    answer = None

    # Analyzer ì‘ë‹µì´ ìˆìœ¼ë©´ ì‚¬ìš©
    if analysis:
        if isinstance(analysis, dict):
            answer = analysis.get("general_answer")
        else:
            answer = getattr(analysis, "general_answer", None)

    # Analyzer ì‘ë‹µì´ ì—†ìœ¼ë©´ intent/í‚¤ì›Œë“œ ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ
    if not answer:
        if "ê³ ë§ˆ" in user_input or "ê°ì‚¬" in user_input:
            answer = GREETING_RESPONSES["thanks"]
        elif "ë„ì›€" in user_input or "help" in user_input or "ë­˜ í•  ìˆ˜" in user_input:
            answer = GREETING_RESPONSES["help"]
        else:
            answer = GREETING_RESPONSES["default"]

    new_state = update_state(
        state,
        current_step="general_response",
        final_output=answer,
        # [FIX] greeting ê²½ë¡œì—ì„œ í•„ìš”í•œ í•„ë“œ ì„¤ì •
        need_more_info=False,
        options=[],
        option_question=None
    )

    return update_step_history(
        new_state,
        "general_response",
        "SUCCESS",
        summary=f"ì‘ë‹µ ì™„ë£Œ (intent={intent or 'analyzer'})"
    )


# =============================================================================
# Chat Response Node (LLM ê¸°ë°˜)
# =============================================================================

def chat_response_node(state: PlanCraftState) -> PlanCraftState:
    """
    LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‘ë‹µ ë…¸ë“œ

    [íŠ¹ì§•]
    - GPT-4o-mini ì‚¬ìš© (ë¹„ìš© íš¨ìœ¨ì )
    - ëŒ€í™” ì´ë ¥ ì°¸ì¡°í•˜ì—¬ ë§¥ë½ ìœ ì§€
    - ë¸Œë ˆì¸ìŠ¤í† ë° ì§€ì›
    - ì ì ˆí•œ ì‹œì ì— ê¸°íšì„œ ì‘ì„± ì œì•ˆ

    [í˜¸ì¶œ ê²½ë¡œ]
    Router â†’ intent="greeting" â†’ chat_response (LLM ëŒ€í™”)
    """
    import time
    start_time = time.time()
    logger = get_file_logger()

    user_input = state.get("user_input", "")
    chat_history = state.get("chat_history", [])

    logger.info(f"[ChatResponse] ëŒ€í™” ìš”ì²­: '{user_input[:50]}...'")

    try:
        from utils.llm import get_llm
        from datetime import datetime

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í˜„ì¬ ë‚ ì§œ ì‚½ì…
        weekdays_kr = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        now = datetime.now()
        today_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekdays_kr[now.weekday()]})"
        system_prompt = CHAT_SYSTEM_PROMPT_TEMPLATE.format(today_date=today_str)

        # ëŒ€í™” ì´ë ¥ êµ¬ì„± (ìµœê·¼ 6ê°œê¹Œì§€)
        messages = [{"role": "system", "content": system_prompt}]

        # ì´ì „ ëŒ€í™” ì¶”ê°€ (ë§¥ë½ ìœ ì§€)
        recent_history = chat_history[-6:] if len(chat_history) > 6 else chat_history
        for msg in recent_history:
            if msg.get("role") in ["user", "assistant"]:
                messages.append({
                    "role": msg["role"],
                    "content": msg.get("content", "")
                })

        # í˜„ì¬ ì…ë ¥ ì¶”ê°€
        messages.append({"role": "user", "content": user_input})

        # LLM í˜¸ì¶œ (gpt-4o-minië¡œ ë¹„ìš© ì ˆê°)
        llm = get_llm(model_type="gpt-4o-mini", temperature=0.7)
        response = llm.invoke(messages)

        answer = response.content if hasattr(response, 'content') else str(response)
        logger.info(f"[ChatResponse] ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(answer)}ì)")

    except Exception as e:
        logger.error(f"[ChatResponse] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ ì‘ë‹µ
        answer = GREETING_RESPONSES["default"]

    new_state = update_state(
        state,
        current_step="chat_response",
        final_output=answer,
        need_more_info=False,
        options=[],
        option_question=None
    )

    return update_step_history(
        new_state,
        "chat_response",
        "SUCCESS",
        summary="LLM ëŒ€í™” ì‘ë‹µ",
        start_time=start_time
    )
