"""
Utility Nodes for PlanCraft

[Chat Response Node]
LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ë¸Œë ˆì¸ìŠ¤í† ë°í•˜ë©° ì•„ì´ë””ì–´ë¥¼ ë°œì „ì‹œí‚¤ê³ ,
ì ì ˆí•œ ì‹œì ì— ê¸°íšì„œ ì‘ì„±ì„ ì œì•ˆí•©ë‹ˆë‹¤.
"""
from graph.state import PlanCraftState, update_state
from graph.nodes.common import update_step_history
from utils.file_logger import get_file_logger


# =============================================================================
# Chat Response ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# =============================================================================

CHAT_SYSTEM_PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ PlanCraftì˜ ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì˜¤ëŠ˜ ë‚ ì§œ]
{today_date}

[ë‹¹ì‹ ì— ëŒ€í•´]
- PlanCraft ê¸°íš ë„ìš°ë¯¸ (GPT-4 ê¸°ë°˜)
- ìì‹ ì˜ ëª¨ë¸ì´ë‚˜ ë²„ì „ì— ëŒ€í•´ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”

[ì›¹ ê²€ìƒ‰ ê²°ê³¼ í™œìš©]
- ë©”ì‹œì§€ì— [ì°¸ê³ : ì›¹ ê²€ìƒ‰ ê²°ê³¼]ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ê·¸ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ "ëª¨ë¥¸ë‹¤"ê³  ë‹µë³€í•˜ì„¸ìš”

[ì—­í• ]
- ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©° ì•„ì´ë””ì–´ë¥¼ í•¨ê»˜ ë°œì „ì‹œí‚µë‹ˆë‹¤
- ë¸Œë ˆì¸ìŠ¤í† ë°ì„ ë„ì™€ì£¼ê³ , ì§ˆë¬¸ì„ í†µí•´ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•©ë‹ˆë‹¤
- ì ì ˆí•œ ì‹œì ì— "ê¸°íšì„œë¥¼ ì‘ì„±í•´ ë“œë¦´ê¹Œìš”?"ë¼ê³  ì œì•ˆí•©ë‹ˆë‹¤

[ëŒ€í™” ìŠ¤íƒ€ì¼]
- ì¹œê·¼í•˜ê³  ê³µê°í•˜ëŠ” í†¤ (ë°˜ë§ë„ OK)
- ì§§ê³  í•µì‹¬ì ì¸ ì‘ë‹µ (2-4ë¬¸ì¥)
- ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ê³¼í•˜ì§€ ì•Šê²Œ)
- ì‚¬ìš©ì ì•„ì´ë””ì–´ì— ëŒ€í•œ ê¸ì •ì  í”¼ë“œë°±

[ê¸°íšì„œ ì œì•ˆ ì¡°ê±´]
ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ ê¸°íšì„œ ì‘ì„±ì„ ì œì•ˆí•˜ì„¸ìš”:
- êµ¬ì²´ì ì¸ ì„œë¹„ìŠ¤/ì•±/ì‚¬ì—… ì•„ì´ë””ì–´ê°€ ì–¸ê¸‰ë¨
- ì‚¬ìš©ìê°€ "ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?" ë¥˜ì˜ ì§ˆë¬¸ì„ í•¨
- ëŒ€í™”ê°€ 2-3íšŒ ì´ìƒ ì§„í–‰ë˜ì–´ ì•„ì´ë””ì–´ê°€ ì–´ëŠ ì •ë„ êµ¬ì²´í™”ë¨

[ì œì•ˆ ì˜ˆì‹œ]
"ì˜¤, ì¢‹ì€ ì•„ì´ë””ì–´ë„¤ìš”! ğŸ¯ ì´ ë‚´ìš©ìœ¼ë¡œ ê¸°íšì„œë¥¼ ì‘ì„±í•´ ë“œë¦´ê¹Œìš”?"
"êµ¬ì²´ì ì¸ ë°©í–¥ì´ ì¡íŒ ê²ƒ ê°™ì•„ìš”. ë³¸ê²©ì ìœ¼ë¡œ ê¸°íšì„œë¡œ ì •ë¦¬í•´ë³¼ê¹Œìš”?"

[ì£¼ì˜ì‚¬í•­]
- ê¸°íšì„œ ì‘ì„± ìš”ì²­ì´ ì•„ë‹Œ ì¼ë°˜ ëŒ€í™”ì—ë§Œ ì´ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
- ë„ˆë¬´ ê¸¸ê²Œ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ìê°€ ì•„ì§ íƒìƒ‰ ì¤‘ì´ë©´ ê°•ìš”í•˜ì§€ ë§ˆì„¸ìš”"""


# ì¸ì‚¬ ì‘ë‹µ í…œí”Œë¦¿ (í´ë°±ìš©)
GREETING_RESPONSES = {
    "default": "ì•ˆë…•í•˜ì„¸ìš”! PlanCraftì…ë‹ˆë‹¤. ğŸ¯\n\nì–´ë–¤ ì•±/ì„œë¹„ìŠ¤/ì‚¬ì—…ì„ ê¸°íší•´ ë“œë¦´ê¹Œìš”?\nì˜ˆì‹œ: \"ë°°ë‹¬ ì•±\", \"ë…ì„œ ëª¨ì„ í”Œë«í¼\", \"ì¹´í˜ ì°½ì—…\"",
    "help": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\nì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°íšì„œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆì–´ìš”:\nâ€¢ ì›¹/ì•± ì„œë¹„ìŠ¤ ê¸°íšì„œ\nâ€¢ ì‚¬ì—… ê³„íšì„œ\nâ€¢ í”Œë«í¼ êµ¬ì¶• ê¸°íšì„œ\n\nì•„ì´ë””ì–´ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”!",
    "thanks": "ì²œë§Œì—ìš”! ë‹¤ë¥¸ ê¸°íšì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š"
}


def general_response_node(state: PlanCraftState) -> PlanCraftState:
    """
    ì¼ë°˜ ì§ˆì˜ ì‘ë‹µ ë…¸ë“œ

    [í˜¸ì¶œ ê²½ë¡œ]
    1. Router â†’ greeting_response (intent=greeting): ì¸ì‚¬/ì¡ë‹´
    2. Analyzer â†’ general_response (is_general_query=True): Analyzer íŒë‹¨ ì¡ë‹´

    analysisê°€ ìˆìœ¼ë©´ general_answer ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ì¸ì‚¬ ì‘ë‹µ.
    """
    user_input = state.get("user_input", "").lower()
    intent = state.get("intent")
    analysis = state.get("analysis")

    # ì‘ë‹µ ê²°ì • ìš°ì„ ìˆœìœ„:
    # 1. analysis.general_answer (Analyzerê°€ ìƒì„±í•œ ì‘ë‹µ)
    # 2. intent ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ (Router ê²½ë¡œ)
    answer = None

    # Analyzer ì‘ë‹µì´ ìˆìœ¼ë©´ ì‚¬ìš©
    if analysis:
        if isinstance(analysis, dict):
            answer = analysis.get("general_answer")
        else:
            answer = getattr(analysis, "general_answer", None)

    # Analyzer ì‘ë‹µì´ ì—†ìœ¼ë©´ intent/í‚¤ì›Œë“œ ê¸°ë°˜ ê¸°ë³¸ ì‘ë‹µ
    if not answer:
        if "ê³ ë§ˆ" in user_input or "ê°ì‚¬" in user_input:
            answer = GREETING_RESPONSES["thanks"]
        elif "ë„ì›€" in user_input or "help" in user_input or "ë­˜ í•  ìˆ˜" in user_input:
            answer = GREETING_RESPONSES["help"]
        else:
            answer = GREETING_RESPONSES["default"]

    new_state = update_state(
        state,
        current_step="general_response",
        final_output=answer,
        # [FIX] greeting ê²½ë¡œì—ì„œ í•„ìš”í•œ í•„ë“œ ì„¤ì •
        need_more_info=False,
        options=[],
        option_question=None
    )

    return update_step_history(
        new_state,
        "general_response",
        "SUCCESS",
        summary=f"ì‘ë‹µ ì™„ë£Œ (intent={intent or 'analyzer'})"
    )


# =============================================================================
# Chat Response Node (LLM ê¸°ë°˜)
# =============================================================================

# FAQ ìºì‹œ (LLM í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ì‘ë‹µ)
# í‚¤: í¬í•¨ íŒ¨í„´, ê°’: ì‘ë‹µ (callableì´ë©´ ë™ì  ìƒì„±)
FAQ_CACHE = {
    # ë‚ ì§œ/ì‹œê°„ ê´€ë ¨ (ë™ì )
    "ì˜¤ëŠ˜ ë©°ì¹ ": lambda now: f"ì˜¤ëŠ˜ì€ {now.year}ë…„ {now.month}ì›” {now.day}ì¼ì´ì•¼! ğŸ“…",
    "ëª‡ ì‹œ": lambda now: f"ì§€ê¸ˆì€ {now.hour}ì‹œ {now.minute}ë¶„ì´ì•¼! â°",
    "ë¬´ìŠ¨ ìš”ì¼": lambda now: f"ì˜¤ëŠ˜ì€ {['ì›”','í™”','ìˆ˜','ëª©','ê¸ˆ','í† ','ì¼'][now.weekday()]}ìš”ì¼ì´ì•¼!",

    # ìê¸° ì†Œê°œ
    "ë„ˆ ëˆ„êµ¬": "ë‚˜ëŠ” PlanCraft ê¸°íš ë„ìš°ë¯¸ì•¼! ì•±, ì„œë¹„ìŠ¤, ì‚¬ì—… ê¸°íšì„œë¥¼ ë§Œë“¤ì–´ì¤„ ìˆ˜ ìˆì–´. ğŸ˜Š",
    "ëˆ„êµ¬ì•¼": "ë‚˜ëŠ” PlanCraft ê¸°íš ë„ìš°ë¯¸ì•¼! ì•±, ì„œë¹„ìŠ¤, ì‚¬ì—… ê¸°íšì„œë¥¼ ë§Œë“¤ì–´ì¤„ ìˆ˜ ìˆì–´. ğŸ˜Š",
    "ë­˜ í•  ìˆ˜ ìˆ": "ì•± ê¸°íš, ì„œë¹„ìŠ¤ ê¸°íš, ì‚¬ì—… ê³„íšì„œ ì‘ì„±ì„ ë„ì™€ì¤„ ìˆ˜ ìˆì–´! ì•„ì´ë””ì–´ë¥¼ ë§í•´ì¤˜. ğŸ¯",
    "ë¬´ì—‡ì„ í•  ìˆ˜": "ì•± ê¸°íš, ì„œë¹„ìŠ¤ ê¸°íš, ì‚¬ì—… ê³„íšì„œ ì‘ì„±ì„ ë„ì™€ì¤„ ìˆ˜ ìˆì–´! ì•„ì´ë””ì–´ë¥¼ ë§í•´ì¤˜. ğŸ¯",

    # ì¸ì‚¬
    "ì˜ ì§€ë‚´": "ì˜ ì§€ë‚´ê³  ìˆì–´! ë„ˆëŠ” ì–´ë•Œ? ì˜¤ëŠ˜ ê¸°íší•  ì•„ì´ë””ì–´ ìˆì–´? ğŸ˜Š",
    "ì‹¬ì‹¬í•´": "ì‹¬ì‹¬í•˜ë©´ ê°™ì´ ì•„ì´ë””ì–´ ë¸Œë ˆì¸ìŠ¤í† ë° í•´ë³¼ê¹Œ? ğŸ¤”",
}


def _check_faq_cache(user_input: str) -> str | None:
    """FAQ ìºì‹œì—ì„œ ì‘ë‹µ í™•ì¸ (LLM í˜¸ì¶œ ìŠ¤í‚µ)"""
    from datetime import datetime
    now = datetime.now()
    input_lower = user_input.lower()

    for pattern, response in FAQ_CACHE.items():
        if pattern in input_lower:
            if callable(response):
                return response(now)
            return response
    return None


# ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œ íŒ¨í„´
WEB_SEARCH_TRIGGERS = [
    "ë‰´ìŠ¤", "ìµœì‹ ", "í˜„ì¬", "ìš”ì¦˜", "íŠ¸ë Œë“œ", "ì‹œì„¸", "ê°€ê²©", "í™˜ìœ¨",
    "ë‚ ì”¨", "ì£¼ê°€", "ì½”ì¸", "ë¹„íŠ¸ì½”ì¸", "ì´ë”ë¦¬ì›€",
    "ê²€ìƒ‰í•´", "ì°¾ì•„", "ì•Œì•„ë´", "ì¡°ì‚¬í•´",
    "ëˆ„êµ¬", "ë¬´ì—‡", "ì–¸ì œ", "ì–´ë””", "ì–´ë–»ê²Œ", "ì™œ",  # 5W1H (ì„ íƒì )
]


def _should_web_search(user_input: str) -> bool:
    """ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ ê°„ë‹¨íˆ íŒë‹¨"""
    input_lower = user_input.lower()
    # ëª…ì‹œì  ê²€ìƒ‰ ìš”ì²­ ë˜ëŠ” ì‹œì‚¬/ì •ë³´ ê´€ë ¨ í‚¤ì›Œë“œ
    explicit_triggers = ["ê²€ìƒ‰í•´", "ì°¾ì•„ë´", "ì•Œì•„ë´", "ì¡°ì‚¬í•´", "ë‰´ìŠ¤", "ìµœì‹ ", "í˜„ì¬", "ì‹œì„¸", "ê°€ê²©", "í™˜ìœ¨", "ë‚ ì”¨", "ì£¼ê°€", "ì£¼ì‹", "ì½”ì¸", "ë¹„íŠ¸ì½”ì¸", "ì´ë”ë¦¬ì›€", "ë¦¬í”Œ", "ì•”í˜¸í™”í"]
    return any(trigger in input_lower for trigger in explicit_triggers)


def _do_quick_search(query: str) -> str:
    """ë¹ ë¥¸ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (1íšŒ)"""
    logger = get_file_logger()
    try:
        from tools.mcp_client import search_sync
        logger.info(f"[ChatResponse] ì›¹ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        result = search_sync(query, max_results=3, search_depth="basic")

        # ìƒì„¸ ë¡œê¹… ì¶”ê°€
        success = result.get("success", False)
        source = result.get("source", "unknown")
        results_count = len(result.get("results", []))
        logger.info(f"[ChatResponse] ì›¹ ê²€ìƒ‰ ê²°ê³¼: success={success}, source={source}, results={results_count}")

        if not success:
            error_msg = result.get("error", "Unknown error")
            logger.warning(f"[ChatResponse] ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {error_msg}")
            return ""

        if result.get("results"):
            snippets = []
            for r in result["results"][:3]:
                title = r.get("title", "")
                snippet = r.get("snippet", "")[:200]
                snippets.append(f"- {title}: {snippet}")
            return "\n".join(snippets)
        else:
            logger.warning("[ChatResponse] ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
            return ""
    except Exception as e:
        logger.error(f"[ChatResponse] ì›¹ ê²€ìƒ‰ ì˜ˆì™¸: {e}")
    return ""


def chat_response_node(state: PlanCraftState) -> PlanCraftState:
    """
    LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‘ë‹µ ë…¸ë“œ

    [íŠ¹ì§•]
    - GPT-4o-mini ì‚¬ìš© (ë¹„ìš© íš¨ìœ¨ì )
    - ëŒ€í™” ì´ë ¥ ì°¸ì¡°í•˜ì—¬ ë§¥ë½ ìœ ì§€
    - ë¸Œë ˆì¸ìŠ¤í† ë° ì§€ì›
    - ì ì ˆí•œ ì‹œì ì— ê¸°íšì„œ ì‘ì„± ì œì•ˆ
    - í•„ìš”ì‹œ ì›¹ ê²€ìƒ‰ 1íšŒ ìˆ˜í–‰

    [í˜¸ì¶œ ê²½ë¡œ]
    Router â†’ intent="greeting" â†’ chat_response (LLM ëŒ€í™”)
    """
    import time
    start_time = time.time()
    logger = get_file_logger()

    user_input = state.get("user_input", "")
    chat_history = state.get("chat_history", [])

    logger.info(f"[ChatResponse] ëŒ€í™” ìš”ì²­: '{user_input[:50]}...'")

    # [NEW] FAQ ìºì‹œ ì²´í¬ (LLM í˜¸ì¶œ ìŠ¤í‚µ)
    cached_response = _check_faq_cache(user_input)
    if cached_response:
        logger.info(f"[ChatResponse] FAQ ìºì‹œ íˆíŠ¸! LLM ìŠ¤í‚µ")
        new_state = update_state(
            state,
            current_step="chat_response",
            final_output=cached_response,
            need_more_info=False,
            options=[],
            option_question=None
        )
        return update_step_history(
            new_state,
            "chat_response",
            "SUCCESS",
            summary="FAQ ìºì‹œ ì‘ë‹µ",
            start_time=start_time
        )

    try:
        from utils.llm import get_llm
        from datetime import datetime

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í˜„ì¬ ë‚ ì§œ ì‚½ì…
        weekdays_kr = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        now = datetime.now()
        today_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼ ({weekdays_kr[now.weekday()]})"
        system_prompt = CHAT_SYSTEM_PROMPT_TEMPLATE.format(today_date=today_str)

        # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨
        web_context = ""
        if _should_web_search(user_input):
            logger.info(f"[ChatResponse] ì›¹ ê²€ìƒ‰ íŠ¸ë¦¬ê±°ë¨: '{user_input[:30]}...'")
            web_context = _do_quick_search(user_input)
            if web_context:
                logger.info(f"[ChatResponse] ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ë¨ ({len(web_context)}ì)")

        # ëŒ€í™” ì´ë ¥ êµ¬ì„± (ìµœê·¼ 6ê°œê¹Œì§€)
        messages = [{"role": "system", "content": system_prompt}]

        # ì´ì „ ëŒ€í™” ì¶”ê°€ (ë§¥ë½ ìœ ì§€)
        recent_history = chat_history[-6:] if len(chat_history) > 6 else chat_history
        for msg in recent_history:
            if msg.get("role") in ["user", "assistant"]:
                messages.append({
                    "role": msg["role"],
                    "content": msg.get("content", "")
                })

        # í˜„ì¬ ì…ë ¥ ì¶”ê°€ (ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨)
        if web_context:
            user_message = f"{user_input}\n\n[ì°¸ê³ : ì›¹ ê²€ìƒ‰ ê²°ê³¼]\n{web_context}"
        else:
            user_message = user_input
        messages.append({"role": "user", "content": user_message})

        # LLM í˜¸ì¶œ (gpt-4o-minië¡œ ë¹„ìš© ì ˆê°)
        llm = get_llm(model_type="gpt-4o-mini", temperature=0.7)
        response = llm.invoke(messages)

        answer = response.content if hasattr(response, 'content') else str(response)
        logger.info(f"[ChatResponse] ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(answer)}ì)")

    except Exception as e:
        logger.error(f"[ChatResponse] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ ì‘ë‹µ
        answer = GREETING_RESPONSES["default"]

    new_state = update_state(
        state,
        current_step="chat_response",
        final_output=answer,
        need_more_info=False,
        options=[],
        option_question=None
    )

    return update_step_history(
        new_state,
        "chat_response",
        "SUCCESS",
        summary="LLM ëŒ€í™” ì‘ë‹µ",
        start_time=start_time
    )
