"""
ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë“ˆ

app.pyì˜ pending_input ì²˜ë¦¬ ë¡œì§ì„ ë¶„ë¦¬í•˜ì—¬ ëª¨ë“ˆí™”í•©ë‹ˆë‹¤.
FastAPI ë°±ì—”ë“œì™€ì˜ í†µì‹ , í´ë§, ê²°ê³¼ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""

import json
import time
from datetime import datetime
from typing import Optional, Dict, Any, Tuple

import httpx
import streamlit as st


from utils.config import Config

# API Base URL - Removed safely
# API_BASE_URL = Config.API_BASE_URL


def check_api_health(timeout: float = 2.0) -> Tuple[bool, str]:
    """
    API ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

    Returns:
        Tuple[bool, str]: (ì •ìƒ ì—¬ë¶€, ì—ëŸ¬ ë©”ì‹œì§€)
    """
    try:
        # /api/v1 ì œê±°í•˜ê³  /health ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
        base_url = Config.API_BASE_URL.replace("/api/v1", "")
        resp = httpx.get(f"{base_url}/health", timeout=timeout)
        if resp.status_code == 200:
            data = resp.json()
            if data.get("service") == "plancraft-api":
                return True, ""
            return False, "ì•Œ ìˆ˜ ì—†ëŠ” ì„œë¹„ìŠ¤ê°€ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤"
        return False, f"ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜ (status={resp.status_code})"
    except httpx.ConnectError:
        return False, "API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
    except httpx.TimeoutException:
        return False, "API ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼"
    except Exception as e:
        return False, f"API ì„œë²„ í™•ì¸ ì‹¤íŒ¨: {e}"


# ë‹¨ê³„ë³„ ì§„í–‰ë¥  ë§¤í•‘
STEP_PROGRESS = {
    "router": 5,                     # [NEW] Smart Router
    "retrieve": 10, "context": 10,
    "analyze": 25,
    "structure": 40,
    "write": 60,
    "review": 75,
    "refine": 85,
    "format": 95,
}

STEP_LABELS = {
    "router": ("ğŸš¦", "ì…ë ¥ ë¶„ë¥˜"),   # [NEW] Smart Router
    "retrieve": ("ğŸ“š", "ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"),
    "context": ("ğŸ“š", "ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"),
    "analyze": ("ğŸ”", "ìš”êµ¬ì‚¬í•­ ë¶„ì„"),
    "structure": ("ğŸ—ï¸", "êµ¬ì¡° ì„¤ê³„"),
    "write": ("âœï¸", "ì½˜í…ì¸  ì‘ì„±"),
    "review": ("ğŸ”", "í’ˆì§ˆ ê²€í† "),
    "refine": ("âœ¨", "ë‚´ìš© ê°œì„ "),
    "format": ("ğŸ“‹", "ìµœì¢… í¬ë§·íŒ…"),
}


def parse_resume_command(pending_text: str) -> Optional[Dict[str, Any]]:
    """
    ì‚¬ìš©ì ì…ë ¥ì—ì„œ Resume ëª…ë ¹ì„ íŒŒì‹±í•©ë‹ˆë‹¤.

    Args:
        pending_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        resume_cmd: Resume ëª…ë ¹ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
    """
    resume_cmd = None

    if pending_text.startswith("FORM_DATA:"):
        try:
            form_data = json.loads(pending_text.replace("FORM_DATA:", ""))
            resume_cmd = {"resume": form_data}
        except (json.JSONDecodeError, ValueError):
            from ui.validation import show_validation_error, ValidationErrorType
            show_validation_error(ValidationErrorType.INVALID_FORMAT, "í¼ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")

    elif pending_text.startswith("OPTION:"):
        try:
            option_data = json.loads(pending_text.replace("OPTION:", ""))
            resume_cmd = {"resume": {"selected_option": option_data}}
        except (json.JSONDecodeError, ValueError):
            from ui.validation import show_validation_error, ValidationErrorType
            show_validation_error(ValidationErrorType.INVALID_FORMAT, "ì„ íƒ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")

    elif st.session_state.current_state and st.session_state.current_state.get("__interrupt__"):
        resume_cmd = {"resume": {"text_input": pending_text}}

    elif st.session_state.current_state and st.session_state.current_state.get("need_more_info"):
        resume_cmd = {"resume": {"text_input": pending_text}}

    return resume_cmd


def execute_workflow_api(
    pending_text: str,
    resume_cmd: Optional[Dict],
    thread_id: str,
    generation_preset: str,
    file_content: Optional[str],
    refine_count: int,
    previous_plan: Optional[str]
) -> httpx.Response:
    """
    ì›Œí¬í”Œë¡œìš° APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

    Args:
        pending_text: ì‚¬ìš©ì ì…ë ¥
        resume_cmd: Resume ëª…ë ¹ (ìˆìœ¼ë©´ ì¬ê°œ, ì—†ìœ¼ë©´ ì‹ ê·œ ì‹¤í–‰)
        thread_id: ìŠ¤ë ˆë“œ ID
        generation_preset: ìƒì„± í”„ë¦¬ì…‹
        file_content: ì—…ë¡œë“œëœ íŒŒì¼ ë‚´ìš©
        refine_count: ê°œì„  íšŸìˆ˜
        previous_plan: ì´ì „ ê¸°íšì„œ

    Returns:
        httpx.Response: API ì‘ë‹µ
    """
    if resume_cmd:
        # Resume ìš”ì²­ (HITL ì¬ê°œ)
        response = httpx.post(
            f"{Config.API_BASE_URL}/workflow/resume",
            json={
                "thread_id": thread_id,
                "resume_data": resume_cmd["resume"],
                "generation_preset": generation_preset,
            },
            timeout=30.0
        )
    else:
        # ì‹ ê·œ ì‹¤í–‰
        response = httpx.post(
            f"{Config.API_BASE_URL}/workflow/run",
            json={
                "user_input": pending_text,
                "file_content": file_content,
                "thread_id": thread_id,
                "generation_preset": generation_preset,
                "refine_count": refine_count,
                "previous_plan": previous_plan
            },
            timeout=30.0
        )

    if response.is_error:
        print(f"[API ERROR] Status: {response.status_code}, Body: {response.text}")
        try:
            error_detail = response.json()
            if "detail" in error_detail:
                from utils.file_logger import logger
                logger.error(f"Validation Detail: {error_detail['detail']}")
                st.error(f"ìš”ì²­ ë°ì´í„° ì˜¤ë¥˜ (Validation Error): {error_detail['detail']}")
        except Exception:
            pass

    response.raise_for_status()
    return response


def poll_workflow_status(
    thread_id: str,
    status_widget,
    progress_bar,
    current_step_display,
    on_log_callback=None  # [NEW] Callback for real-time logging
) -> Tuple[Dict[str, Any], list]:
    """
    ì›Œí¬í”Œë¡œìš° ìƒíƒœë¥¼ í´ë§í•˜ì—¬ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.

    Args:
        thread_id: ìŠ¤ë ˆë“œ ID
        status_widget: Streamlit status ìœ„ì ¯
        progress_bar: ì§„í–‰ë¥  ë°”
        current_step_display: í˜„ì¬ ë‹¨ê³„ í‘œì‹œ ìœ„ì ¯
        on_log_callback: ë¡œê·¸ ë°œìƒ ì‹œ í˜¸ì¶œí•  ì½œë°± í•¨ìˆ˜

    Returns:
        Tuple[final_result, execution_log]: ìµœì¢… ê²°ê³¼ì™€ ì‹¤í–‰ ë¡œê·¸
    """
    MAX_POLL_DURATION = 600  # ìµœëŒ€ 10ë¶„
    MAX_CONSECUTIVE_ERRORS = 10
    POLL_INTERVAL = 1.0
    INITIAL_WAIT_TIME = 5.0

    last_step_count = 0
    final_result = None
    start_time = time.time()
    execution_log = []
    consecutive_errors = 0
    current_progress = 0

    while True:
        elapsed = int(time.time() - start_time)

        # íƒ€ì„ì•„ì›ƒ ì²´í¬
        if elapsed > MAX_POLL_DURATION:
            raise TimeoutError(f"ì‘ì—… ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤ ({MAX_POLL_DURATION}ì´ˆ)")

        # ìƒíƒœ ì¡°íšŒ
        try:
            status_res = httpx.get(
                f"{Config.API_BASE_URL}/workflow/status/{thread_id}",
                timeout=10.0
            )

            if status_res.status_code == 404:
                if elapsed < INITIAL_WAIT_TIME:
                    current_step_display.markdown("â³ **ì´ˆê¸°í™” ì¤‘...** ì›Œí¬í”Œë¡œìš°ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤")
                    time.sleep(POLL_INTERVAL)
                    continue
                raise ValueError("ì›Œí¬í”Œë¡œìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            elif status_res.status_code >= 500:
                consecutive_errors += 1
                if consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                    raise RuntimeError(f"ì„œë²„ ì˜¤ë¥˜ê°€ ê³„ì† ë°œìƒí•©ë‹ˆë‹¤ ({consecutive_errors}íšŒ)")
                time.sleep(POLL_INTERVAL * 2)
                continue
            elif status_res.status_code != 200:
                consecutive_errors += 1
                time.sleep(POLL_INTERVAL)
                continue

            consecutive_errors = 0

        except httpx.RequestError as e:
            consecutive_errors += 1
            if consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                raise ConnectionError(f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {e}")
            time.sleep(POLL_INTERVAL)
            continue

        status_data = status_res.json()
        current_status = status_data.get("status", "running")
        step_history = status_data.get("step_history", [])
        current_step = status_data.get("current_step", "")

        # í˜„ì¬ ë‹¨ê³„ ì—…ë°ì´íŠ¸
        for step_key, progress in STEP_PROGRESS.items():
            if current_step and step_key in current_step.lower():
                if progress > current_progress:
                    current_progress = progress
                    progress_bar.progress(min(current_progress / 100, 0.95))
                    icon, label = STEP_LABELS.get(step_key, ("â–¶ï¸", current_step))
                    status_widget.update(label=f"{icon} {label} ({elapsed}ì´ˆ)", state="running")
                    current_step_display.markdown(f"ğŸŸ¢ **ì§„í–‰ ì¤‘:** {label} ë‹¨ê³„")
                break

        # ë¡œê·¸ ìˆ˜ì§‘ & ì½œë°± ì‹¤í–‰ (Step History + Execution Log)
        # 1. Step History ì²˜ë¦¬
        if len(step_history) > last_step_count:
            new_steps = step_history[last_step_count:]
            last_step_count = len(step_history)
            
            for step in new_steps:
                step_name = step.get("step", "Unknown")
                summary = step.get("summary", "")
                exec_time = step.get("execution_time", "")
                
                icon = "âœ”"
                for key, (ic, _) in STEP_LABELS.items():
                    if key in step_name.lower():
                        icon = ic
                        break
                        
                log_entry = {
                    "step": step_name,
                    "summary": f"[{icon}] {step_name} ì™„ë£Œ: {summary} ({exec_time})",
                    "timestamp": time.time()
                }
                if not on_log_callback:
                     status_widget.write(log_entry["summary"])
                
                execution_log.append(log_entry)
                
                if on_log_callback:
                    # [FIX] ë¬¸ìì—´ ëŒ€ì‹  Dict ê°ì²´ ì „ì²´ ì „ë‹¬ (TypeError í•´ê²°)
                    on_log_callback({
                        "step": step_name,
                        "icon": icon,
                        "summary": summary
                    })

        # 2. Execution Log (Real-time Events) ì²˜ë¦¬
        server_exec_log = status_data.get("execution_log", [])
        current_exec_log_count = getattr(poll_workflow_status, "last_exec_log_count", 0)
        
        if len(server_exec_log) > current_exec_log_count:
            new_events = server_exec_log[current_exec_log_count:]
            poll_workflow_status.last_exec_log_count = len(server_exec_log)
            
            for event in new_events:
                msg = event.get("message", "")
                if msg:
                     if not on_log_callback:
                         status_widget.write(f"  â†³ {msg}")
                     
                     if on_log_callback:
                         # [FIX] Real-time eventë„ Dict í˜•íƒœë¡œ ì „ë‹¬
                         on_log_callback({
                             "step": "Running",
                             "icon": "âš¡",
                             "summary": msg
                         })




        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        if current_status in ["completed", "interrupted", "failed"]:
            final_result = status_data.get("result")
            if not final_result:
                time.sleep(0.5)
                retry_res = httpx.get(
                    f"{Config.API_BASE_URL}/workflow/status/{thread_id}",
                    timeout=5.0
                )
                if retry_res.status_code == 200:
                    final_result = retry_res.json().get("result")
            if not final_result:
                raise Exception("ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        time.sleep(POLL_INTERVAL)

    return final_result, execution_log


def handle_workflow_result(final_result: Dict[str, Any], status_data: Dict = None):
    """
    ì›Œí¬í”Œë¡œìš° ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
        final_result: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼
        status_data: ìƒíƒœ ë°ì´í„° (í† í° ì‚¬ìš©ëŸ‰ ë“±)
    """
    # API ì‘ë‹µ í•„ë“œ ë§¤í•‘
    if final_result.get("interrupt"):
        final_result["__interrupt__"] = final_result["interrupt"]

    # ê²°ê³¼ State ì €ì¥
    st.session_state.current_state = final_result
    current_refine_count = st.session_state.get("next_refine_count", 0)
    if current_refine_count > 0:
        final_result["refine_count"] = current_refine_count
        st.session_state.next_refine_count = 0

    # ê²°ê³¼ ë¶„ì„
    analysis_res = final_result.get("analysis")
    generated_plan = final_result.get("final_output", "")
    interrupt_data = final_result.get("__interrupt__")

    # ìƒíƒœê°’ ì´ˆê¸°í™”
    options = final_result.get("options", [])
    option_question = final_result.get("option_question", "ë‹¤ìŒê³¼ ê°™ì´ ê¸°íš ë°©í–¥ì„ ì œì•ˆí•©ë‹ˆë‹¤.")

    # ì¸í„°ëŸ½íŠ¸ê°€ ìˆìœ¼ë©´ Payload ë°ì´í„°ë¡œ ë®ì–´ì“°ê¸°
    if interrupt_data:
        if "question" in interrupt_data:
            option_question = interrupt_data["question"]
        if "options" in interrupt_data:
            options = interrupt_data["options"]

    is_general = False
    if analysis_res and isinstance(analysis_res, dict):
        is_general = analysis_res.get("is_general_query", False)

    # [NEW] Router intent í™•ì¸ (greeting/info_queryëŠ” ì±„íŒ… ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬)
    intent = final_result.get("intent")
    is_chat_response = intent in ("greeting", "info_query")

    # ê²°ê³¼ ìœ í˜•ë³„ ì²˜ë¦¬
    if is_chat_response:
        _handle_greeting_result(generated_plan or "ì•ˆë…•í•˜ì„¸ìš”!")
    elif options and len(options) > 0 and not is_general:
        _handle_options_result(options, option_question, analysis_res)
    elif is_general:
        _handle_general_result(analysis_res)
    elif generated_plan:
        _handle_plan_result(generated_plan, final_result, status_data)
    else:
        st.session_state.chat_history.append({
            "role": "assistant", "content": "ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", "type": "text"
        })


def _handle_options_result(options: list, option_question: str, analysis_res: dict):
    """ì˜µì…˜ ì„ íƒ ê²°ê³¼ ì²˜ë¦¬"""
    preview_msg = ""
    if analysis_res:
        p_topic = analysis_res.get("topic", "ë¯¸ì •")
        p_purpose = analysis_res.get("purpose", "")
        p_features = analysis_res.get("key_features", [])

        preview_msg += f"**ğŸ“Œ ì œì•ˆ ì»¨ì…‰**: {p_topic}\n"
        preview_msg += f"**ğŸ¯ ê¸°íš ì˜ë„**: {p_purpose}\n"
        if p_features:
            feats = ", ".join(p_features[:4])
            preview_msg += f"**ğŸ’¡ ì£¼ìš” ê¸°ëŠ¥**: {feats} ë“±\n"
        preview_msg += "\n"

    msg = f"ğŸ¤” {option_question}\n\n{preview_msg}"
    msg_content = msg
    for o in options:
        msg_content += f"- **{o.get('title')}**: {o.get('description')}\n"

    st.session_state.chat_history.append({
        "role": "assistant", "content": msg_content, "type": "options"
    })


def _handle_general_result(analysis_res: dict):
    """ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ì²˜ë¦¬"""
    ans = analysis_res.get("general_answer", "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    st.session_state.chat_history.append({
        "role": "assistant", "content": ans, "type": "text"
    })
    st.session_state.generated_plan = None


def _handle_greeting_result(response: str):
    """
    ì¸ì‚¬/ì¡ë‹´ ì‘ë‹µ ì²˜ë¦¬ (Smart Router greeting intent)

    Routerê°€ greetingìœ¼ë¡œ ë¶„ë¥˜í•œ ê²½ìš° í˜¸ì¶œë©ë‹ˆë‹¤.
    ê¸°íšì„œ ìƒì„± ì—†ì´ ì±„íŒ… ì‘ë‹µë§Œ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    st.session_state.chat_history.append({
        "role": "assistant", "content": response, "type": "text"
    })
    # ê¸°íšì„œ ì˜ì—­ ì´ˆê¸°í™” (ì´ì „ ê¸°íšì„œê°€ ìˆì–´ë„ ìƒˆ greetingì—ì„œëŠ” í‘œì‹œ ì•ˆ í•¨)
    # st.session_state.generated_plan = None  # ì´ì „ ê¸°íšì„œëŠ” ìœ ì§€


def _handle_plan_result(generated_plan: str, final_result: dict, status_data: dict = None):
    """ê¸°íšì„œ ì™„ì„± ê²°ê³¼ ì²˜ë¦¬"""
    st.session_state.generated_plan = generated_plan

    # í”„ë¦¬ì…‹ ë° í† í° ì‚¬ìš©ëŸ‰ ì •ë³´
    from utils.settings import get_preset
    preset_key = st.session_state.get("generation_preset", "balanced")
    preset = get_preset(preset_key)
    usage_info = f"\n\n---\nğŸ¤– **ì‚¬ìš© ëª¨ë¸**: {preset.model_type} ({preset.name})"

    token_usage = final_result.get("token_usage")
    if status_data:
        token_usage = token_usage or status_data.get("token_usage")

    if token_usage and token_usage.get("total_tokens", 0) > 0:
        usage_info += f"\nğŸ“Š **í† í° ì‚¬ìš©ëŸ‰**: {token_usage['total_tokens']:,}ê°œ"
        usage_info += f" (ì…ë ¥: {token_usage['input_tokens']:,}, ì¶œë ¥: {token_usage['output_tokens']:,})"
        usage_info += f"\nğŸ’° **ì˜ˆìƒ ë¹„ìš©**: ${token_usage['estimated_cost_usd']:.4f}"
        usage_info += f" (ì•½ {int(token_usage['estimated_cost_krw'])}ì›)"

    st.session_state.chat_history.append({
        "role": "assistant",
        "content": f"âœ… ê¸°íšì„œê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!{usage_info}",
        "type": "plan"
    })

    st.session_state.trigger_notification = True

    # íˆìŠ¤í† ë¦¬ ì €ì¥
    now_str = datetime.now().strftime("%H:%M:%S")
    if not st.session_state.plan_history or st.session_state.plan_history[-1]['content'] != generated_plan:
        st.session_state.plan_history.append({
            "version": len(st.session_state.plan_history) + 1,
            "timestamp": now_str,
            "content": generated_plan
        })

    # ì±„íŒ… ìš”ì•½ ì¶”ê°€
    chat_summary = final_result.get("chat_summary", "")
    if chat_summary:
        st.session_state.chat_history.append({
            "role": "assistant", "content": chat_summary, "type": "summary"
        })


def run_pending_workflow(pending_text: str, status_placeholder):
    """
    ëŒ€ê¸° ì¤‘ì¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        pending_text: ì‚¬ìš©ì ì…ë ¥
        status_placeholder: ìƒíƒœ í‘œì‹œ placeholder
    """
    # Resume ëª…ë ¹ íŒŒì‹±
    resume_cmd = parse_resume_command(pending_text)

    with status_placeholder.container():
        with st.status("ğŸš€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...", expanded=True) as status:
            try:
                file_content = st.session_state.get("uploaded_content", None)
                current_refine_count = st.session_state.get("next_refine_count", 0)
                previous_plan = st.session_state.generated_plan
                thread_id = st.session_state.thread_id
                generation_preset = st.session_state.get("generation_preset", "balanced")

                # [NEW] API ì„œë²„ ìƒíƒœ í™•ì¸
                api_ok, api_error = check_api_health()
                if not api_ok:
                    status.update(label="âŒ API ì„œë²„ ì—°ê²° ì‹¤íŒ¨", state="error", expanded=True)
                    st.error(f"ğŸ”Œ {api_error}")
                    st.info("ğŸ’¡ **í•´ê²° ë°©ë²•:**\n- í„°ë¯¸ë„ì—ì„œ ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”\n- ì•±ì„ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì„œë²„ ì¬ì‹œì‘ì„ ì‹œë„í•˜ì„¸ìš”")
                    return

                # API í˜¸ì¶œ
                status.write("ğŸ”„ ì‘ì—… ìš”ì²­ì„ ì „ì†¡ ì¤‘ì…ë‹ˆë‹¤...")
                
                # [NEW] ìŠ¤ì¼ˆë ˆí†¤ ë¡œë”© í‘œì‹œ
                skeleton_placeholder = status.empty()
                skeleton_placeholder.markdown("""
                <div style="margin: 1rem 0;">
                    <div class="skeleton skeleton-title" style="height: 1.2rem; width: 60%; margin-bottom: 0.5rem; background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%); background-size: 200% 100%; animation: shimmer 1.5s ease-in-out infinite; border-radius: 4px;"></div>
                    <div class="skeleton skeleton-text" style="height: 0.8rem; width: 80%; margin-bottom: 0.3rem; background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%); background-size: 200% 100%; animation: shimmer 1.5s ease-in-out infinite; border-radius: 4px;"></div>
                    <div class="skeleton skeleton-text" style="height: 0.8rem; width: 70%; background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%); background-size: 200% 100%; animation: shimmer 1.5s ease-in-out infinite; border-radius: 4px;"></div>
                </div>
                <style>
                    @keyframes shimmer { 0% { background-position: -200% 0; } 100% { background-position: 200% 0; } }
                </style>
                """, unsafe_allow_html=True)
                
                execute_workflow_api(
                    pending_text, resume_cmd, thread_id,
                    generation_preset, file_content,
                    current_refine_count, previous_plan
                )

                # [FIX] Resume í›„ ìƒíƒœê°€ ë³€ê²½ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                # Background taskê°€ ì‹œì‘ë˜ì–´ ìƒíƒœê°€ "running"ìœ¼ë¡œ ë³€ê²½ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
                if resume_cmd:
                    status.write("â³ ì¬ê°œ ì²˜ë¦¬ ì¤‘...")
                    for _ in range(10):  # ìµœëŒ€ 5ì´ˆ ëŒ€ê¸°
                        time.sleep(0.5)
                        check_res = httpx.get(
                            f"{Config.API_BASE_URL}/workflow/status/{thread_id}",
                            timeout=5.0
                        )
                        if check_res.status_code == 200:
                            check_status = check_res.json().get("status", "")
                            if check_status == "running":
                                break  # ìƒíƒœê°€ runningìœ¼ë¡œ ë³€ê²½ë¨

                # ìŠ¤ì¼ˆë ˆí†¤ ì œê±°
                skeleton_placeholder.empty()

                # ì§„í–‰ë¥  UI
                progress_bar = status.progress(0)
                current_step_display = status.empty()
                
                # [FIX] st.empty()ë¡œ ë³€ê²½ - ë§¤ë²ˆ ì§€ìš°ê³  ë‹¤ì‹œ ê·¸ë¦¬ê¸°
                log_placeholder = status.empty()
                visible_logs = []  # ì „ì²´ ë¡œê·¸ ì €ì¥
                
                def on_log_update(log_entry):
                    """ì‹¤ì‹œê°„ ë¡œê·¸ ì—…ë°ì´íŠ¸ (ìµœê·¼ 3ê°œë§Œ í‘œì‹œ, ë‚˜ë¨¸ì§€ ì ‘í˜)"""
                    nonlocal visible_logs
                    visible_logs.append(log_entry)
                    
                    # placeholder ì™„ì „íˆ ì§€ìš°ê³  ë‹¤ì‹œ ë Œë”ë§
                    with log_placeholder.container():
                        # 5ê°œ ì´ˆê³¼ ì‹œ "ì´ì „ ë¡œê·¸ ë³´ê¸°" í‘œì‹œ
                        if len(visible_logs) > 5:
                            with st.expander(f"ğŸ“œ ì´ì „ ë‹¨ê³„ ({len(visible_logs) - 5}ê°œ)", expanded=False):
                                for old_log in visible_logs[:-5]:
                                    summary_short = old_log['summary'][:40] + "..." if len(old_log['summary']) > 40 else old_log['summary']
                                    st.caption(f"âœ“ {old_log['step']} â€” {summary_short}")
                        
                        # ìµœê·¼ 5ê°œ ë¡œê·¸ë§Œ í‘œì‹œ
                        recent_logs = visible_logs[-5:]
                        for log in recent_logs:
                            st.markdown(f"**{log['icon']} {log['step'].upper()}** â€” {log['summary']}")

                # í´ë§
                final_result, execution_log = poll_workflow_status(
                    thread_id, status, progress_bar, current_step_display,
                    on_log_callback=on_log_update  # ì½œë°± ì „ë‹¬
                )

                # ì™„ë£Œ ìƒíƒœ í‘œì‹œ
                progress_bar.progress(100)
                start_time = time.time()
                total_elapsed = int(time.time() - start_time)
                current_step_display.empty()

                if execution_log:
                    # status.markdown(f"âœ… **ì™„ë£Œ** â€” ì´ {len(execution_log)}ë‹¨ê³„ ì‹¤í–‰ë¨") # ì¤‘ë³µ ì œê±°
                    pass

                status.update(label=f"âœ… ì™„ë£Œ! (ì´ {total_elapsed}ì´ˆ)", state="complete", expanded=False)

                # ê²°ê³¼ ì²˜ë¦¬
                handle_workflow_result(final_result)

                # Mermaid ë‹¤ì´ì–´ê·¸ë¨ í‘œì‹œ
                if final_result.get("_plan"):
                    from agents.agent_config import export_plan_to_mermaid
                    mermaid_code = export_plan_to_mermaid(final_result["_plan"])
                    if mermaid_code:
                        with st.expander("ğŸ”— ì‹¤í–‰ ê³„íš ë‹¤ì´ì–´ê·¸ë¨ (Mermaid)", expanded=True):
                            from ui.components import render_scalable_mermaid
                            render_scalable_mermaid(mermaid_code, height=400)
                            st.caption("Supervisorê°€ ìˆ˜ë¦½í•˜ê³  ì‹¤í–‰í•œ ì—ì´ì „íŠ¸ í˜‘ì—… êµ¬ì¡°ë„ì…ë‹ˆë‹¤.")

                st.rerun()

            except Exception as e:
                # [DEBUG] ìƒì„¸ ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥
                import traceback
                trace_str = traceback.format_exc()
                print(f"[CRITICAL ERROR] {trace_str}") 
                with st.expander("ğŸš¨ ë””ë²„ê·¸ìš© ìƒì„¸ ì—ëŸ¬ ë¡œê·¸ (Traceback)", expanded=True):
                    st.code(trace_str)

                from ui.validation import handle_exception_friendly, detect_error_type, ERROR_MESSAGES

                handle_exception_friendly(e, context="ê¸°íšì„œ ìƒì„± ì¤‘")

                if st.session_state.current_state:
                    if isinstance(st.session_state.current_state, dict):
                        st.session_state.current_state.update({
                            "error": str(e), "step_status": "FAILED"
                        })

                error_type = detect_error_type(e)
                error_info = ERROR_MESSAGES.get(error_type, ERROR_MESSAGES[error_type.UNKNOWN])
                friendly_msg = f"{error_info['icon']} **{error_info['title']}**\n\n"
                friendly_msg += f"{error_info['message']}\n\n{error_info['hint']}"

                st.session_state.chat_history.append({
                    "role": "assistant", "content": friendly_msg, "type": "error"
                })
