{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document & Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고**\n",
    "\n",
    "- [LangChain 에서 사용되는 주요 로더](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/)\n",
    "- [LangChain 에서 사용되는 로더 목록](https://python.langchain.com/v0.1/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습에 활용할 문서\n",
    "\n",
    "정보통신정책연구원(KISDI) - 2025년 1월호\n",
    "\n",
    "- 제목 : 딥시크가 촉발한 AI 패러다임 변화와 정책 방향\n",
    "\n",
    "- 파일명: `AI_Paradigm_Shift_Driven_by_DeepSeek.pdf`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document\n",
    "\n",
    "LangChain 의 기본 문서 객체입니다.\n",
    "\n",
    "**속성**\n",
    "- `page_content`: 문서의 내용을 나타내는 문열입니다.\n",
    "- `metadata`: 문서의 메타데이터를 나타내는 딕셔너리입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document = Document(page_content=\"안녕하세요? 이건 랭체인의 도큐먼드 입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {},\n",
       " 'page_content': '안녕하세요? 이건 랭체인의 도큐먼드 입니다',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도큐먼트의 속성 확인\n",
    "document.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 추가\n",
    "document.metadata[\"source\"] = \"AI Talent Lab\"\n",
    "document.metadata[\"page\"] = 1\n",
    "document.metadata[\"author\"] = \"bokyung\"\n",
    "document.metadata[\"date\"] = \"2025-03-07\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'AI Talent Lab',\n",
       " 'page': 1,\n",
       " 'author': 'bokyung',\n",
       " 'date': '2025-03-07'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도큐먼트의 속성 확인\n",
    "document.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loader\n",
    "\n",
    "다양한 파일의 형식으로부터 불러온 내용을 문서(Document) 객체로 변환하는 역할을 합니다.\n",
    "\n",
    "### 주요 Loader \n",
    "- PyPDFLoader: PDF 파일을 로드하는 로더입니다.\n",
    "- CSVLoader: CSV 파일을 로드하는 로더입니다.\n",
    "- UnstructuredHTMLLoader: HTML 파일을 로드하는 로더입니다.\n",
    "- JSONLoader: JSON 파일을 로드하는 로더입니다.\n",
    "- TextLoader: 텍스트 파일을 로드하는 로더입니다.\n",
    "- DirectoryLoader: 디렉토리를 로드하는 로더입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 파일 경로\n",
    "FILE_PATH = \"./data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 로더 설정\n",
    "loader = PyPDFLoader(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load()\n",
    "\n",
    "- 문서를 로드하여 반환합니다.\n",
    "- 반환된 결과는 `List[Document]` 형태입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF 로더\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서의 수 확인\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Hancom PDF 1.3.0.509', 'creator': 'Hancom PDF 1.3.0.509', 'creationdate': '2025-02-10T17:02:50+09:00', 'author': 'Insung-9', 'moddate': '2025-02-10T17:02:50+09:00', 'pdfversion': '1.4', 'source': './data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf', 'total_pages': 46, 'page': 10, 'page_label': '11'}, page_content=\"딥시크가 촉발한 AI 패러다임 변화와 플랫폼 정책방향\\n10\\nl(애플리케이션) ’24.2월 기존 바드(Bard)를 통합한 생성형 AI 앱 ‘제미나이’ 출시, 다양한 기능을 지속 탑재하여 성능 개선-생산성 플랫폼 Workspace, 웹브라우저 Chrome 등에 제미나이 통합-이용자 질문에 대한 심층연구 실행을 돕는 AI 에이전트 ‘제미나이 딥 리서치’ 출시-’24.5월 차세대 범용 AI 에이전트 ‘프로젝트 아스트라’ 공개, ’25년 상용화 예정-검색에서 사용자와 상호작용 및 후속질문이 가능한 AI기반 챗봇 및 멀티모달 방식을 도입할 계획-검색에서 실시간 비디오 처리나 연구보고서 생성도 추진◆ 메타l(기초 모델) LLaMA를 연구 용도 중심의 비영리 라이센스로 전 세계 AI 커뮤니티에 제공하고 개방형 협력을 구하는 전략으로 접근l(애플리케이션) SNS 관련 앱 전반에 AI를 직접 통합하여 광범위한 이용자 데이터를 바탕으로 새로운 형태의 광고 도구를 제공하는 플랫폼으로 확장시킬 계획-’24.4월 멀티모달 AI 비서 '메타 AI'를 무료로 공개하여 페이스북, 인스타그램, 왓츠앱 등을 통해 사용할 수 있음-’24.7월 AI 캐릭터와 챗봇을 만들 수 있는 ‘AI 스튜디오' 출시\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 번째 문서 확인\n",
    "docs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_and_split()\n",
    "\n",
    "- splitter 를 사용하여 문서를 분할하고 반환합니다.\n",
    "- 반환된 결과는 `List[Document]` 형태입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 길이: 207\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문열 분할기 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "\n",
    "# 예제 파일 경로\n",
    "FILE_PATH = \"./data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\"\n",
    "\n",
    "# 로더 설정\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "# 문서 분할\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# 로드된 문서의 수 확인\n",
    "print(f\"문서의 길이: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Hancom PDF 1.3.0.509', 'creator': 'Hancom PDF 1.3.0.509', 'creationdate': '2025-02-10T17:02:50+09:00', 'author': 'Insung-9', 'moddate': '2025-02-10T17:02:50+09:00', 'pdfversion': '1.4', 'source': './data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf', 'total_pages': 46, 'page': 13, 'page_label': '14'}, page_content='(2) 국내 플랫폼 기업의 AI 전략◆ 네이버l(기초 모델) ’23.8월 자체 모델 ‘하이퍼클로바’ 공개, ’24.8월 버전을 높인 ’하이퍼클로바X’ 발표, ’25.2월 플래그십 모델 업데이트 예정※ 네이버 서비스에 최적화된 모델의 능력과 속도를 효율적으로 구축하는 것이 목표l(애플리케이션) ’24.8월 생성형 AI앱 ’클로바X’ 이미지 해석 기능 개선')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50번째 문서 확인\n",
    "split_docs[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "\n",
    "[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), ISO 32000으로 표준화된 파일 형식은 Adobe가 1992년에 문서를 제시하기 위해 개발했으며, 이는 응용 소프트웨어, 하드웨어 및 운영 시스템에 독립적인 방식으로 텍스트 서식 및 이미지를 포함합니다.\n",
    "\n",
    "현실에서는 많은 문서들이 PDF 형태로 전달이 되곤 합니다.\n",
    "\n",
    "해당 실습에서는 `PDF` 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) 형식으로 로드하는 방법을 다룹니다.\n",
    "\n",
    "LangChain은 다양한 PDF 파서와 통합되어 있어서 간단하게 사용할 수 있지만, OCR이 필요한 경우에는 한글 인식에 대한 성능이 부족하기도 합니다. \n",
    "\n",
    "다양한 PDF 라이브러리를 적용해보고 그 결과를 비교하면서 내가 만들어야할 어플리케이션에 적합한 라이브러리를 선택해야합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [LangChain 도큐먼트](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoRAG 팀에서의 PDF 실험\n",
    "\n",
    "AutoRAG 에서 진행한 실험을 토대로 작성한 순위표\n",
    "\n",
    "아래 표기된 숫자는 등수를 나타냅니다. (The lower, the better)\n",
    "\n",
    "| | PDFMiner | PDFPlumber | PyPDFium2 | PyMuPDF | PyPDF2 |\n",
    "|----------|:---------:|:----------:|:---------:|:-------:|:-----:|\n",
    "| Medical  | 1         | 2          | 3         | 4       | 5     |\n",
    "| Law      | 3         | 1          | 1         | 3       | 5     |\n",
    "| Finance  | 1         | 2          | 2         | 4       | 5     |\n",
    "| Public   | 1         | 1          | 1         | 4       | 5     |\n",
    "| Sum      | 5         | 5          | 7         | 15      | 20    |\n",
    "\n",
    "출처: [AutoRAG Medium 블로그](https://velog.io/@autorag/PDF-%ED%95%9C%EA%B8%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%B6%94%EC%B6%9C-%EC%8B%A4%ED%97%98#%EC%B4%9D%ED%8F%89)\n",
    "\n",
    "이 외에도 Azure의 Document Intelligence, Amazon Textract 등 MSP에서 제공하고 있는 문서 인식, 처리를 위한 서비스를 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사전 준비\n",
    "\n",
    "생성된 Document 객체에 대한 상세 정보를 확인하기 위한 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDF\n",
    "\n",
    "여기에서는 `pypdf`를 사용하여 PDF를 문서 배열로 로드하며, 각 문서는 `page` 번호와 함께 페이지 내용 및 메타데이터를 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install langchain-community \n",
    "# !pip3 install -qU pypdf\n",
    "# !pip3 install pillow\n",
    "# !apt-get update && apt-get install libgl1 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "searchable pdf인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "딥시크가 촉발한 AI 패러다임 변화와 플랫폼 정책방향\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 설정\n",
    "FILE_PATH = \"./data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\"\n",
    "\n",
    "# PDF 로더 초기화\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "# 문서의 내용 출력\n",
    "print(docs[4].page_content[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'pdfversion', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.509\n",
      "creator      : Hancom PDF 1.3.0.509\n",
      "creationdate : 2025-02-10T17:02:50+09:00\n",
      "author       : Insung-9\n",
      "moddate      : 2025-02-10T17:02:50+09:00\n",
      "pdfversion   : 1.4\n",
      "source       : ./data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\n",
      "total_pages  : 46\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 출력\n",
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 스캔된 문서와 같은 image-based pdf인 경우 pypdfloader를 이용하면 page content를 추출할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 6, 'page_label': '7'}, page_content=''), Document(metadata={'producer': 'Lexmark X652de', 'creator': 'HardCopy', 'creationdate': '2015-11-12T15:39:07-06:00', 'moddate': '2015-11-12T15:39:07-06:00', 'title': 'Scanned Document', 'source': './data/extract_text/PublicWaterMassMailing.pdf', 'total_pages': 8, 'page': 7, 'page_label': '8'}, page_content='')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH_OCR = \"./data/extract_text/PublicWaterMassMailing.pdf\"\n",
    "\n",
    "# 파일 경로 설정\n",
    "loader = PyPDFLoader(FILE_PATH_OCR)\n",
    "\n",
    "# PDF 로더 초기화\n",
    "docs = loader.load()\n",
    "print(docs)\n",
    "# 문서의 내용 출력\n",
    "print(docs[1].page_content[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- image based pdf는 단순 pdf loader로는 컨텐츠가 제대로 추출되지 않을 수 있습니다.\n",
    "\n",
    "- 이 때는 rapidocr-onnxruntime 을 설치하면 이미지에서 텍스트를 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rapidocr_onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `extract_images=True`로 설정하면 이미지로 되어있는 pdf 안의 text를 추출할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contractoperatorswill beprovidedwithformsforall th\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH_OCR = \"./data/extract_text/PublicWaterMassMailing.pdf\"\n",
    "\n",
    "# 파일 경로 설정\n",
    "loader = PyPDFLoader(FILE_PATH_OCR, extract_images=True)\n",
    "\n",
    "# PDF 로더 초기화\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[1].page_content[:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMuPDF\n",
    "\n",
    "**PyMuPDF** 는 속도 최적화가 되어 있으며, PDF 및 해당 페이지에 대한 자세한 메타데이터를 포함하고 있습니다. 페이지 당 하나의 문서를 반환합니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "#!pip install -qU pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MissouriDepartmentof HealthandSeniorServices\n",
      "DHSS\n",
      "P.O.Box570.JeffersonCity,MO65102-0570Phone:573-751-6400FAX:573-751-6010\n",
      "RELAYMISSOURIforHearing andSpeechImpaired1-800-735-2966VOICE1-800-735-2466\n",
      "PeterLyskowski\n",
      "JeremiahW.(Jay)Nixon\n",
      "Acting Director\n",
      "Governor\n",
      "MissouriPublicWaterSystems\n",
      "November 10,201\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = \"./data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\"\n",
    "FILE_PATH_OCR = \"./data/extract_text/PublicWaterMassMailing.pdf\"\n",
    "\n",
    "# PyMuPDF 로더 인스턴스 생성\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "loader = PyMuPDFLoader(FILE_PATH_OCR, extract_images=True) \n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n",
    "# show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDFium2\n",
    "\n",
    "PyPDFium2도 마찬가지로 `extract_image=True`로 설정하면 이미지로된 pdf에서 텍스트를 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdfium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jupyter/dvenv/lib/python3.12/site-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥시크가 촉발한 AI 패러다임 변화와 플랫폼 정책방향\n",
      "10\n",
      "l (애플리케이션) ’24.2월 기존 바드(Bard)를 통합한 생성형 AI 앱 \n",
      "‘제미나이’ 출시, 다양한 기능을 지속 탑재하여 성능 개선\n",
      "- 생산성 플랫폼 Workspace, 웹브라우저 Chrome 등에 제미나이 통합\n",
      "- 이용자 질문에 대한 심층연구 실행을 돕는 AI 에이전트 ‘제미나이 \n",
      "딥 리서치’ 출시\n",
      "- ’24.5월 차세대 범용 AI 에이전트 ‘프로젝트 아스트라’ 공개, ’25년 \n",
      "상용화 예정\n",
      "- 검색에서 사용자와 상호작용 및 후속질문이 가능한 AI기반 챗봇 \n",
      "및 멀\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = \"./data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\"\n",
    "FILE_PATH_OCR = \"./data/extract_text/PublicWaterMassMailing.pdf\"\n",
    "\n",
    "loader = PyPDFium2Loader(FILE_PATH)\n",
    "# loader = PyPDFium2Loader(FILE_PATH_OCR, extract_images=True)\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFPlumber\n",
    "PyMuPDF와 마찬가지로, 출력 문서는 PDF와 그 페이지에 대한 자세한 메타데이터를 포함하며, 페이지 당 하나의 문서를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MissouriDepartmentof HealthandSeniorServices\n",
      "DHSS\n",
      "P.O.Box570.JeffersonCity,MO65102-0570Phone:573-751-6400FAX:573-751-6010\n",
      "RELAYMISSOURIforHearing andSpeechImpaired1-800-735-2966VOICE1-800-735-2466\n",
      "PeterLyskowski\n",
      "JeremiahW.(Jay)Nixon\n",
      "Acting Director\n",
      "Governor\n",
      "MissouriPublicWaterSystems\n",
      "November 10,20\n",
      "[metadata]\n",
      "['source', 'file_path', 'page', 'total_pages', 'CreationDate', 'Creator', 'ModDate', 'Producer', 'Title']\n",
      "\n",
      "[examples]\n",
      "source       : ./data/extract_text/PublicWaterMassMailing.pdf\n",
      "file_path    : ./data/extract_text/PublicWaterMassMailing.pdf\n",
      "page         : 0\n",
      "total_pages  : 8\n",
      "CreationDate : D:20151112153907-06'00'\n",
      "Creator      : HardCopy\n",
      "ModDate      : D:20151112153907-06'00'\n",
      "Producer     : Lexmark X652de\n",
      "Title        : Scanned Document\n"
     ]
    }
   ],
   "source": [
    "# FILE_PATH = \"../data/extract_text/AI_Paradigm_Shift_Driven_by_DeepSeek.pdf\"\n",
    "FILE_PATH_OCR = \"./data/extract_text/PublicWaterMassMailing.pdf\"\n",
    "\n",
    "# LangChain PDFPlumberLoader 활용\n",
    "# loader = PyPDFium2Loader(FILE_PATH)\n",
    "loader = PDFPlumberLoader(FILE_PATH_OCR, extract_images=True)\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n",
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "\n",
    "[Comma-Separated Values (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) 파일은 쉼표로 값을 구분하는 구분된 텍스트 파일입니다. 파일의 각 줄은 데이터 레코드입니다. \n",
    "\n",
    "각 레코드는 쉼표로 구분된 하나 이상의 필드로 구성됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVLoader\n",
    "\n",
    "- CSV 데이터를 문서당 한 행씩 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "{'source': './data/extract_text/titanic.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# CSV 로더 생성\n",
    "loader = CSVLoader(file_path=\"./data/extract_text/titanic.csv\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId: 2\n",
      "Survived: 1\n",
      "Pclass: 1\n",
      "Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
      "Sex: female\n",
      "Age: 38\n",
      "SibSp: 1\n",
      "Parch: 0\n",
      "Ticket: PC 17599\n",
      "Fare: 71.2833\n",
      "Cabin: C85\n",
      "Embarked: C\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 파싱 및 로딩 커스터마이징\n",
    "\n",
    "[csv module](https://docs.python.org/3/library/csv.html) 문서를 참조하여 지원되는 **csv args**에 대한 자세한 정보를 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger ID: 1\n",
      "Survival (1: Survived, 0: Died): 0\n",
      "Passenger Class: 3\n",
      "Name: Braund, Mr. Owen Harris\n",
      "Sex: male\n",
      "Age: 22\n",
      "Number of Siblings/Spouses Aboard: 1\n",
      "Number of Parents/Children Aboard: 0\n",
      "Ticket Number: A/5 21171\n",
      "Fare: 7.25\n",
      "Cabin: \n",
      "Port of Embarkation: S\n"
     ]
    }
   ],
   "source": [
    "# 컬럼정보:\n",
    "# PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "\n",
    "# CSV 파일 경로\n",
    "loader = CSVLoader(\n",
    "    file_path=\"./data/extract_text/titanic.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",  # 구분자\n",
    "        \"quotechar\": '\"',  # 인용 부호 문자\n",
    "        \"fieldnames\": [\n",
    "            \"Passenger ID\",\n",
    "            \"Survival (1: Survived, 0: Died)\",\n",
    "            \"Passenger Class\",\n",
    "            \"Name\",\n",
    "            \"Sex\",\n",
    "            \"Age\",\n",
    "            \"Number of Siblings/Spouses Aboard\",\n",
    "            \"Number of Parents/Children Aboard\",\n",
    "            \"Ticket Number\",\n",
    "            \"Fare\",\n",
    "            \"Cabin\",\n",
    "            \"Port of Embarkation\",\n",
    "        ],  # 필드 이름\n",
    "    },\n",
    ")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 데이터 출력\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습용 AOAI 환경변수 읽기\n",
    "import os\n",
    "\n",
    "AOAI_ENDPOINT=os.getenv(\"AOAI_ENDPOINT\")\n",
    "AOAI_API_KEY=os.getenv(\"AOAI_API_KEY\")\n",
    "AOAI_DEPLOY_GPT4O=os.getenv(\"AOAI_DEPLOY_GPT4O\")\n",
    "AOAI_DEPLOY_GPT4O_MINI=os.getenv(\"AOAI_DEPLOY_GPT4O_MINI\")\n",
    "AOAI_DEPLOY_EMBED_3_LARGE=os.getenv(\"AOAI_DEPLOY_EMBED_3_LARGE\")\n",
    "AOAI_DEPLOY_EMBED_3_SMALL=os.getenv(\"AOAI_DEPLOY_EMBED_3_SMALL\")\n",
    "AOAI_DEPLOY_EMBED_ADA=os.getenv(\"AOAI_DEPLOY_EMBED_ADA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=AOAI_ENDPOINT,\n",
    "    azure_deployment=AOAI_DEPLOY_GPT4O_MINI,\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=AOAI_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./data/extract_text/flowchart.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 확인\n",
    "from IPython.display import display, Image\n",
    "\n",
    "image_path = \"./data/extract_text/flowchart.jpg\"\n",
    "display(Image(url=image_path, width=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "# 이미지를 base64로 인코딩하는 함수\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    " \n",
    "# base64 문자열 얻기\n",
    "base64_image = encode_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG (Retrieval-Augmented Generation) Pipeline Flowchart를 분석하여 각 단계의 작업, 흐름, 결정 및 전체 프로세스를 설명하겠습니다.\n",
      "\n",
      "### 1. 주요 노드 식별 및 의미 설명\n",
      "\n",
      "- **PDF**: 사용자 입력 문서 형태로, 분석할 내용을 담고 있는 파일입니다.\n",
      "  \n",
      "- **Document Loader and Text Splitter**: PDF 문서를 로드하고 텍스트를 분할하는 역할을 합니다. 이를 통해 PDF 내의 정보가 관리 가능한 텍스트 청크로 나누어집니다.\n",
      "\n",
      "- **Text Chunks**: 로드된 PDF에서 분할된 문서 조각을 나타냅니다. 이 단계에서 여러 개의 텍스트 청크가 생성됩니다.\n",
      "\n",
      "- **Embedding Generation Model**: 각 텍스트 청크를 벡터로 변환하여 의미 있는 임베딩(벡터 표현)을 생성하는 모델입니다.\n",
      "\n",
      "- **Embeddings**: 텍스트 청크의 의미적인 표현으로, 벡터 데이터베이스에 저장됩니다.\n",
      "\n",
      "- **Vector Database**: 생성된 임베딩 벡터를 저장하고 관리하는 장소입니다. 사용자가 질의할 때 이 데이터베이스에서 정보를 조회합니다.\n",
      "\n",
      "- **Query**: 사용자가 입력하는 질문이나 요청으로, 데이터베이스와 상호작용할 정보를 제공합니다.\n",
      "\n",
      "- **Similarity Search**: 사용자의 질의와 가장 유사한 k개의 결과를 찾아내는 과정입니다.\n",
      "\n",
      "- **Answer**: 최종적으로 사용자가 요청한 질문에 대한 응답입니다.\n",
      "\n",
      "- **LLM (Large Language Model)**: 사용자의 질의를 처리하고 답변을 생성하는 역할을 합니다.\n",
      "\n",
      "### 2. 화살표 흐름에 따른 실행 과정 분석\n",
      "\n",
      "1. **PDF** → **Document Loader and Text Splitter**\n",
      "   - 사용자가 제공한 PDF를 로드하고 텍스트 내용을 청크로 나눕니다.\n",
      "\n",
      "2. **Document Loader and Text Splitter** → **Text Chunks**\n",
      "   - PDF에서 여러 개의 텍스트 청크가 생성됩니다.\n",
      "\n",
      "3. **Text Chunks** → **Embedding Generation Model**\n",
      "   - 생성된 텍스트 청크는 임베딩 생성 모델에 입력되어 벡터로 변환됩니다.\n",
      "\n",
      "4. **Embedding Generation Model** → **Embeddings**\n",
      "   - 모델이 처리한 결과로 각 텍스트 청크에 대한 임베딩이 생성됩니다.\n",
      "\n",
      "5. **Embeddings** → **Vector Database**\n",
      "   - 생성된 임베딩 벡터는 벡터 데이터베이스에 저장됩니다.\n",
      "\n",
      "6. **User** → **Query**\n",
      "   - 사용자가 특정 질문을 입력합니다.\n",
      "\n",
      "7. **Query** → **Embedding Generation Model**\n",
      "   - 사용자 질의도 임베딩 생성 모델을 통해 벡터로 변환됩니다.\n",
      "\n",
      "8. **Query Embedding** → **Similarity Search**\n",
      "   - 사용자 질의의 임베딩을 기반으로 데이터베이스에서 가장 유사한 k개의 결과를 탐색합니다.\n",
      "\n",
      "9. **Top-k matches** → **LLM**\n",
      "   - 유사한 결과가 LLM에 전달되어, 이 데이터를 기반으로 응답을 생성합니다.\n",
      "\n",
      "10. **Answer** → **User**\n",
      "   - 최종적으로 생성된 답변이 사용자에게 제공됩니다.\n",
      "\n",
      "### 3. 특정 결정(Decision) 설명\n",
      "\n",
      "이 Flowchart 내에서는 명백한 결정 노드가 보이지 않으나, \"Similarity search\" 단계에서의 k-match 결과는 질의와의 유사도에 따라 다르게 진행됩니다. 따라서 사용자의 질의 결과에 따라 다수의 결과가 존재할 수 있으며, 이를 통해 적절한 답변을 선택하거나 생성하는 과정이 결정됩니다.\n",
      "\n",
      "### 4. 전체 프로세스 요약\n",
      "\n",
      "이 Flowchart는 RAG Pipeline의 전반적인 구조를 설명합니다. 사용자는 PDF 형식의 문서를 제출하고, 시스템은 이 문서를 로드하여 텍스트 청크로 분할한 후, 임베딩 모델을 통해 벡터를 생성하고 벡터 데이터베이스에 저장합니다. 이후 사용자가 입력한 질의를 벡터로 변환하여 데이터베이스에서 유사한 결과를 검색하고, 이 정보를 기반으로 LLM이 답변을 생성하여 사용자에게 전달하는 과정을 보여줍니다. 전반적으로, 이 프로세스는 사용자 질문에 대한 빠르고 정확한 정보를 제공하기 위해 텍스트 데이터의 검색 및 생성 기술을 활용하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt = \"\"\"Flowchart를 해석하고 노드 간 관계 및 의미를 추출하는 분석가입니다.\n",
    "flowchart를 분석하여 각 단계에서 수행되는 작업과 전체적인 프로세스를 설명해주세요.\n",
    "\n",
    "1. Flowchart 내 주요 노드(작업, 결정 등)를 식별하고, 해당하는 의미를 자세히 설명해주세요.\n",
    "2. 화살표(→)가 가리키는 흐름을 따라 순서대로 실행 과정을 분석해주세요.\n",
    "3. 특정 결정(Decision)이 존재하는 경우, 각각의 조건에서 어떤 경로로 진행되는지 설명해주세요.\n",
    "4. 최종적으로 이 Flowchart가 설명하는 전체 프로세스를 요약해주세요.\n",
    "\"\"\"\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": prompt},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "    ],\n",
    ")\n",
    "response = model.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
