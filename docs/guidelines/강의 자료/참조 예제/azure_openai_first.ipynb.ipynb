{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30ZXnJREIGjd"
   },
   "source": [
    "# OpenAI API 기초 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcfOGd0_IGjf"
   },
   "source": [
    "## 1. openai python sdk 설치\n",
    "- openai api는 파이썬용 SDK 를 설치하거나 HTTP Client 를 사용하여 REST API 를 직접 호출하는 방식으로 사용할 수 있습니다.\n",
    "- 프로그래밍 언어 선택에 제약이 있는 경우를 제외하면 대부분 파이썬 SDK 를 설치하여 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI 리소스 정보 설정\n",
    "- openai API 를 호출하기 위해서는 API key 를 입력해야합니다.\n",
    "- Azure OpenAI 의 경우, API key 뿐만 아니라 endpoint, deployment name 등이 추가로 필요합니다.\n",
    "- 이 실습 환경에서는 Azure OpenAI 를 사용하기 위해 필요한 정보를 환경변수로 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습용 AOAI 환경변수 읽기\n",
    "import os\n",
    "\n",
    "AOAI_ENDPOINT=os.getenv(\"AOAI_ENDPOINT\")\n",
    "AOAI_API_KEY=os.getenv(\"AOAI_API_KEY\")\n",
    "AOAI_DEPLOY_GPT4O=os.getenv(\"AOAI_DEPLOY_GPT4O\")\n",
    "AOAI_DEPLOY_GPT4O_MINI=os.getenv(\"AOAI_DEPLOY_GPT4O_MINI\")\n",
    "AOAI_DEPLOY_EMBED_3_LARGE=os.getenv(\"AOAI_DEPLOY_EMBED_3_LARGE\")\n",
    "AOAI_DEPLOY_EMBED_3_SMALL=os.getenv(\"AOAI_DEPLOY_EMBED_3_SMALL\")\n",
    "AOAI_DEPLOY_EMBED_ADA=os.getenv(\"AOAI_DEPLOY_EMBED_ADA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 간단한 Chat Completion 구현\n",
    "- AzureOpenAI 클라이언트를 생성하고 chat completions create 를 호출하여 간단히 GPT 의 응답을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 어떻게 도와드릴까요?\n",
      "CompletionUsage(completion_tokens=10, prompt_tokens=20, total_tokens=30, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = AOAI_ENDPOINT, \n",
    "  api_key=AOAI_API_KEY,  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=AOAI_DEPLOY_GPT4O_MINI,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)    # LLM 답변\n",
    "print(response.usage)                         # 토큰 사용량\n",
    "print(response.prompt_filter_results)         # 프롬프트 필터 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Modal (GPT-Vision) 구현\n",
    "- o1, GPT-4o, GPT-4o-mini 및 GPT-4 Turbo with Vision 모델은 이미지를 분석하여 자연어로 답변할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img.animalplanet.co.kr/news/2019/11/28/700/f9in35p5660ce423x290.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 확인\n",
    "from IPython.display import display, Image\n",
    "\n",
    "image_url = \"https://img.animalplanet.co.kr/news/2019/11/28/700/f9in35p5660ce423x290.jpg\"\n",
    "display(Image(url=image_url, width=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지에는 흰색 털을 가진 귀여운 동물의 귀 부분이 보입니다. 배경은 흐릿하며 실내 또는 외부의 어두운 환경으로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=AOAI_DEPLOY_GPT4O,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"이미지를 설명해줘\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": image_url\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 로컬 파일을 활용한 이미지 분석\n",
    "- Base64 이미지로 변환하면 로컬 이미지도 분석할 수 있습니다.\n",
    "- 공식 문서를 참고하면 쉽게 구현할 수 있습니다. (https://learn.microsoft.com/ko-kr/azure/ai-services/openai/how-to/gpt-with-vision?tabs=rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'langchain_toolcalling.ipynb',\n",
       " 'test.png',\n",
       " 'azure_openai_first.ipynb',\n",
       " 'langchain_multimodal.ipynb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data URL: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA5wAAALfCAIAAACCa1rwAAAAAXNSR0IArs4c6QAAAHhlWElmTU0AKg\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "\n",
    "# Example usage\n",
    "image_path = 'test.png'\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "print(\"Data URL:\", data_url[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 이미지는 마이크로서비스 아키텍처의 한 예를 보여줍니다. 다음과 같은 구성 요소들이 포함되어 있습니다:\n",
      "\n",
      "1. **Service 1, Service 2, Service 3**: 이들은 각각 독립적으로 운영되는 마이크로서비스입니다. 각 서비스는 특정 기능을 수행하며, 서로 협력하여 전체 시스템을 구성합니다.\n",
      "\n",
      "2. **HTTP Gateway**: 이 구성 요소는 클라이언트 요청을 받고 이를 적절한 서비스로 라우팅하는 역할을 합니다. 즉, 클라이언트는 HTTP Gateway에 요청을 보내고, Gateway가 해당 요청을 적절한 서비스로 전달합니다.\n",
      "\n",
      "3. **Database 1, Database 2, Database 3**: 각각의 서비스는 독립적인 데이터베이스와 연결되어 있습니다. 이러한 데이터베이스는 각 서비스의 데이터를 저장하고 관리합니다.\n",
      "\n",
      "4. **화살표**: 화살표는 서비스와 데이터베이스 간의 관계를 나타냅니다. 서비스가 특정 데이터베이스에 접근하거나 데이터를 주고받는 방식을 시각적으로 표현합니다.\n",
      "\n",
      "전체적으로, 이 그림은 마이크로서비스들이 HTTP Gateway를 통해 서로 소통하고, 각 서비스가 독자적으로 데이터베이스에 접근하는 구조를 나타내고 있습니다. 이러한 아키텍처는 시스템의 확장성과 유지보수성을 높이기 위해 자주 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=AOAI_DEPLOY_GPT4O_MINI,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"이미지를 설명해줘\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 대화 이력\n",
    "- 문맥을 유지하며 대화하기 위해서는 대화 이력이 관리되어야합니다.\n",
    "- messages에 프롬프트들을 추가하여 LLM 호출 시 대화 이력을 주입할 수 있습니다.\n",
    "- \"system\" : 시스템 프롬프트 (o1, o3 의 경우 \"developer\" 로 변경되었습니다.)\n",
    "- \"user\" : 사용자 메시지\n",
    "- \"assistant\": LLM 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 서울에는 멋진 여행지가 많이 있습니다. 다음은 서울의 추천 여행지입니다:\n",
      "\n",
      "1. **경복궁**: 조선 왕조의 주요 궁궐 중 하나로, 아름다운 건축물과 정원을 감상할 수 있습니다. 근처의 국립민속박물관도 함께 방문해보세요.\n",
      "\n",
      "2. **남산서울타워**: 서울의 랜드마크 중 하나로, 전망대에서 서울의 전경을 감상할 수 있습니다. 케이블카로 올라가는 재미도 있습니다.\n",
      "\n",
      "3. **명동**: 쇼핑과 먹거리가 풍부한 유흥가로, 다양한 상점들과 맛있는 길거리 음식을 즐길 수 있습니다.\n",
      "\n",
      "4. **인사동**: 전통 문화와 현대 미술이 어우러진 거리로, 기념품 가게와 전통 찻집이 많아 다양한 경험을 할 수 있습니다.\n",
      "\n",
      "5. **홍대**: 젊은이들의 문화가 흐르는 지역으로, 예술적인 거리와 다양한 음식점, 카페들이 있어 활기찬 분위기를 즐길 수 있습니다.\n",
      "\n",
      "6. **한강공원**: 한강을 따라 조성된 공원으로, 자전거 타기, 산책, 피크닉 등을 즐길 수 있는 좋은 장소입니다.\n",
      "\n",
      "7. **북촌 한옥마을**: 전통 한옥들이 모여있는 지역으로, 한국의 전통 건축을 감상할 수 있으며, 예쁜 골목길이 인상적입니다.\n",
      "\n",
      "8. **동대문 디자인 플라자(DDP)**: 현대적인 건축물로, 전시회와 이벤트가 자주 열리며, 주변의 동대문 시장도 인기입니다.\n",
      "\n",
      "이 외에도 서울에는 다양한 박물관, 갤러리, 전통시장 등이 있어 즐길 거리가 많습니다. 방문할 때마다 새로운 매력을 발견할 수 있을 거예요!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=AOAI_DEPLOY_GPT4O_MINI,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"대한민국의 수도는 어디야?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"대한민국의 수도는 서울입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"그곳의 여행지를 추천해줄래?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
