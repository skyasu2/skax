import time
from typing import Any, Dict, List, Optional
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult

# í† í°ë‹¹ ë¹„ìš© (USD) - GPT-4o ê¸°ì¤€
COST_PER_INPUT_TOKEN = 2.5 / 1_000_000  # $2.5 per 1M tokens
COST_PER_OUTPUT_TOKEN = 10 / 1_000_000  # $10 per 1M tokens


class TokenTrackingCallback(BaseCallbackHandler):
    """
    API í™˜ê²½ì—ì„œ í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•˜ëŠ” ì½œë°±.
    Streamlit ì˜ì¡´ì„± ì—†ì´ í† í° ì‚¬ìš©ëŸ‰ë§Œ ì¶”ì í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.llm_call_count = 0

    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        """LLM í˜¸ì¶œ ì‹œìž‘"""
        self.llm_call_count += 1

    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """LLM í˜¸ì¶œ ì™„ë£Œ - í† í° ì¶”ì """
        try:
            if response.llm_output:
                usage = response.llm_output.get("token_usage", {})
                self.total_input_tokens += usage.get("prompt_tokens", 0)
                self.total_output_tokens += usage.get("completion_tokens", 0)
        except Exception:
            pass

    def get_usage_summary(self) -> dict:
        """í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½"""
        total_tokens = self.total_input_tokens + self.total_output_tokens
        estimated_cost = (
            self.total_input_tokens * COST_PER_INPUT_TOKEN +
            self.total_output_tokens * COST_PER_OUTPUT_TOKEN
        )
        return {
            "input_tokens": self.total_input_tokens,
            "output_tokens": self.total_output_tokens,
            "total_tokens": total_tokens,
            "llm_calls": self.llm_call_count,
            "estimated_cost_usd": round(estimated_cost, 4),
            "estimated_cost_krw": round(estimated_cost * 1350, 0)
        }

# ë‹¨ê³„ë³„ í‘œì‹œ ì •ë³´ (key, icon, label, progress%)
STEP_INFO = {
    "context": ("ðŸ“š", "ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘", 10),
    "analyze": ("ðŸ”", "ìš”êµ¬ì‚¬í•­ ë¶„ì„", 20),
    "structure": ("ðŸ—ï¸", "êµ¬ì¡° ì„¤ê³„", 35),
    "write": ("âœï¸", "ì½˜í…ì¸  ìž‘ì„±", 55),
    "review": ("ðŸ“‹", "í’ˆì§ˆ ê²€í† ", 70),
    "discuss": ("ðŸ’¬", "ì—ì´ì „íŠ¸ í† ë¡ ", 75),
    "refine": ("ðŸ”§", "ë‚´ìš© ê°œì„ ", 85),
    "format": ("ðŸ“„", "ìµœì¢… í¬ë§·íŒ…", 95),
}


class StreamlitStatusCallback(BaseCallbackHandler):
    """
    LangChain/LangGraph ì‹¤í–‰ ê³¼ì •ì„ Streamlit st.statusì— ì‹¤ì‹œê°„ í‘œì‹œ.

    st.status íŠ¹ì„±:
    - status.update(label=...) â†’ ì‹¤ì‹œê°„ ë°˜ì˜ âœ…
    - status.progress() â†’ ì‹¤ì‹œê°„ ë°˜ì˜ âœ…
    - ë‚´ë¶€ markdown/write â†’ ì™„ë£Œ í›„ì—ë§Œ í‘œì‹œ âŒ

    ë”°ë¼ì„œ labelê³¼ progressë§Œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """

    def __init__(self, status_container):
        self.status = status_container
        self.start_time = time.time()

        # ì§„í–‰ë¥  ë°”
        self.progress_bar = self.status.progress(0)

        # ì‹¤í–‰ ê¸°ë¡ (ì™„ë£Œ í›„ í‘œì‹œìš©)
        self.execution_log: List[tuple] = []
        self.current_step_key: Optional[str] = None
        self.step_start_time: Optional[float] = None

        # í† í° ì¶”ì 
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.llm_call_count = 0

    def set_step(self, step_key: str):
        """í˜„ìž¬ ë‹¨ê³„ ì„¤ì • - labelê³¼ progress ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"""
        # ì´ì „ ë‹¨ê³„ ì™„ë£Œ ê¸°ë¡
        if self.current_step_key and self.step_start_time:
            elapsed = round(time.time() - self.step_start_time, 1)
            self.execution_log.append((self.current_step_key, elapsed))

        # ìƒˆ ë‹¨ê³„ ì‹œìž‘
        self.current_step_key = step_key
        self.step_start_time = time.time()

        # ë‹¨ê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        info = STEP_INFO.get(step_key)
        if info:
            icon, label, progress = info
            total_elapsed = int(time.time() - self.start_time)

            # âœ… ì‹¤ì‹œê°„ ë°˜ì˜ë˜ëŠ” ì—…ë°ì´íŠ¸
            self.status.update(
                label=f"{icon} {label} ({total_elapsed}ì´ˆ ê²½ê³¼)",
                state="running"
            )
            self.progress_bar.progress(progress / 100)

    def finish(self):
        """ì™„ë£Œ ì²˜ë¦¬ - ìµœì¢… ë¡œê·¸ í‘œì‹œ"""
        # ë§ˆì§€ë§‰ ë‹¨ê³„ ê¸°ë¡
        if self.current_step_key and self.step_start_time:
            elapsed = round(time.time() - self.step_start_time, 1)
            self.execution_log.append((self.current_step_key, elapsed))
            self.current_step_key = None

        total_elapsed = int(time.time() - self.start_time)

        # ì§„í–‰ë¥  100%
        self.progress_bar.progress(100)

        # ì™„ë£Œ í›„ ì‹¤í–‰ ë¡œê·¸ í‘œì‹œ (ì´ì œ í‘œì‹œë¨)
        if self.execution_log:
            log_text = "**ì‹¤í–‰ ì™„ë£Œ:**\n\n"
            for step_key, elapsed in self.execution_log:
                info = STEP_INFO.get(step_key, ("â–¶ï¸", step_key, 0))
                icon, label, _ = info
                log_text += f"âœ… {icon} {label} - {elapsed}s\n\n"
            self.status.markdown(log_text)

        # ì™„ë£Œ ìƒíƒœ
        self.status.update(
            label=f"âœ… ì™„ë£Œ! (ì´ {total_elapsed}ì´ˆ)",
            state="complete"
        )

    # =========================================================================
    # LangChain ì½œë°± ë©”ì„œë“œ
    # =========================================================================

    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        """LLM í˜¸ì¶œ ì‹œìž‘"""
        self.llm_call_count += 1

    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """LLM í˜¸ì¶œ ì™„ë£Œ - í† í° ì¶”ì """
        try:
            if response.llm_output:
                usage = response.llm_output.get("token_usage", {})
                self.total_input_tokens += usage.get("prompt_tokens", 0)
                self.total_output_tokens += usage.get("completion_tokens", 0)
        except Exception:
            pass

    def on_tool_start(
        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any
    ) -> None:
        pass

    def on_agent_action(self, action: Any, **kwargs: Any) -> Any:
        pass

    def custom_log(self, message: str, icon: str = "â„¹ï¸"):
        """í•˜ìœ„ í˜¸í™˜ìš©"""
        pass

    def get_usage_summary(self) -> dict:
        """í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½"""
        total_tokens = self.total_input_tokens + self.total_output_tokens
        estimated_cost = (
            self.total_input_tokens * COST_PER_INPUT_TOKEN +
            self.total_output_tokens * COST_PER_OUTPUT_TOKEN
        )
        return {
            "input_tokens": self.total_input_tokens,
            "output_tokens": self.total_output_tokens,
            "total_tokens": total_tokens,
            "llm_calls": self.llm_call_count,
            "estimated_cost_usd": round(estimated_cost, 4),
            "estimated_cost_krw": round(estimated_cost * 1350, 0)
        }

    def get_execution_summary(self) -> List[dict]:
        """ì‹¤í–‰ ë¡œê·¸ ìš”ì•½"""
        return [
            {"step": step, "elapsed": elapsed}
            for step, elapsed in self.execution_log
        ]
